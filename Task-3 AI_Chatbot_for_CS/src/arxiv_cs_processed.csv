id,title,authors,abstract,published,categories,pdf_url,processed_abstract
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
2503.22679v1,Q-Insight: Understanding Image Quality via Visual Reinforcement Learning,"['Weiqi Li', 'Xuanyu Zhang', 'Shijie Zhao', 'Yabin Zhang', 'Junlin Li', 'Li Zhang', 'Jian Zhang']","Image quality assessment (IQA) focuses on the perceptual visual quality of images, playing a crucial role in downstream tasks such as image reconstruction, compression, and generation. The rapid advancement of multi-modal large language models (MLLMs) has significantly broadened the scope of IQA, moving toward comprehensive image quality understanding that incorporates content analysis, degradation perception, and comparison reasoning beyond mere numerical scoring. Previous MLLM-based methods typically either generate numerical scores lacking interpretability or heavily rely on supervised fine-tuning (SFT) using large-scale annotated datasets to provide descriptive assessments, limiting their flexibility and applicability. In this paper, we propose Q-Insight, a reinforcement learning-based model built upon group relative policy optimization (GRPO), which demonstrates strong visual reasoning capability for image quality understanding while requiring only a limited amount of rating scores and degradation labels. By jointly optimizing score regression and degradation perception tasks with carefully designed reward functions, our approach effectively exploits their mutual benefits for enhanced performance. Extensive experiments demonstrate that Q-Insight substantially outperforms existing state-of-the-art methods in both score regression and degradation perception tasks, while exhibiting impressive zero-shot generalization to comparison reasoning tasks. Code will be available at https://github.com/lwq20020127/Q-Insight.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22679v1,image quality assessment iqa focus perceptual visual quality image playing crucial role downstream task image reconstruction compression generation rapid advancement multimodal large language model mllms significantly broadened scope iqa moving toward comprehensive image quality understanding incorporates content analysis degradation perception comparison reasoning beyond mere numerical scoring previous mllmbased method typically either generate numerical score lacking interpretability heavily rely supervised finetuning sft using largescale annotated datasets provide descriptive assessment limiting flexibility applicability paper propose qinsight reinforcement learningbased model built upon group relative policy optimization grpo demonstrates strong visual reasoning capability image quality understanding requiring limited amount rating score degradation label jointly optimizing score regression degradation perception task carefully designed reward function approach effectively exploit mutual benefit enhanced performance extensive experiment demonstrate qinsight substantially outperforms existing stateoftheart method score regression degradation perception task exhibiting impressive zeroshot generalization comparison reasoning task code available httpsgithubcomlwq20020127qinsight
2503.22677v1,DSO: Aligning 3D Generators with Simulation Feedback for Physical Soundness,"['Ruining Li', 'Chuanxia Zheng', 'Christian Rupprecht', 'Andrea Vedaldi']","Most 3D object generators focus on aesthetic quality, often neglecting physical constraints necessary in applications. One such constraint is that the 3D object should be self-supporting, i.e., remains balanced under gravity. Prior approaches to generating stable 3D objects used differentiable physics simulators to optimize geometry at test-time, which is slow, unstable, and prone to local optima. Inspired by the literature on aligning generative models to external feedback, we propose Direct Simulation Optimization (DSO), a framework to use the feedback from a (non-differentiable) simulator to increase the likelihood that the 3D generator outputs stable 3D objects directly. We construct a dataset of 3D objects labeled with a stability score obtained from the physics simulator. We can then fine-tune the 3D generator using the stability score as the alignment metric, via direct preference optimization (DPO) or direct reward optimization (DRO), a novel objective, which we introduce, to align diffusion models without requiring pairwise preferences. Our experiments show that the fine-tuned feed-forward generator, using either DPO or DRO objective, is much faster and more likely to produce stable objects than test-time optimization. Notably, the DSO framework works even without any ground-truth 3D objects for training, allowing the 3D generator to self-improve by automatically collecting simulation feedback on its own outputs.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22677v1,3d object generator focus aesthetic quality often neglecting physical constraint necessary application one constraint 3d object selfsupporting ie remains balanced gravity prior approach generating stable 3d object used differentiable physic simulator optimize geometry testtime slow unstable prone local optimum inspired literature aligning generative model external feedback propose direct simulation optimization dso framework use feedback nondifferentiable simulator increase likelihood 3d generator output stable 3d object directly construct dataset 3d object labeled stability score obtained physic simulator finetune 3d generator using stability score alignment metric via direct preference optimization dpo direct reward optimization dro novel objective introduce align diffusion model without requiring pairwise preference experiment show finetuned feedforward generator using either dpo dro objective much faster likely produce stable object testtime optimization notably dso framework work even without groundtruth 3d object training allowing 3d generator selfimprove automatically collecting simulation feedback output
2503.22678v1,Self-Evolving Multi-Agent Simulations for Realistic Clinical Interactions,"['Mohammad Almansoori', 'Komal Kumar', 'Hisham Cholakkal']","In this work, we introduce MedAgentSim, an open-source simulated clinical environment with doctor, patient, and measurement agents designed to evaluate and enhance LLM performance in dynamic diagnostic settings. Unlike prior approaches, our framework requires doctor agents to actively engage with patients through multi-turn conversations, requesting relevant medical examinations (e.g., temperature, blood pressure, ECG) and imaging results (e.g., MRI, X-ray) from a measurement agent to mimic the real-world diagnostic process. Additionally, we incorporate self improvement mechanisms that allow models to iteratively refine their diagnostic strategies. We enhance LLM performance in our simulated setting by integrating multi-agent discussions, chain-of-thought reasoning, and experience-based knowledge retrieval, facilitating progressive learning as doctor agents interact with more patients. We also introduce an evaluation benchmark for assessing the LLM's ability to engage in dynamic, context-aware diagnostic interactions. While MedAgentSim is fully automated, it also supports a user-controlled mode, enabling human interaction with either the doctor or patient agent. Comprehensive evaluations in various simulated diagnostic scenarios demonstrate the effectiveness of our approach. Our code, simulation tool, and benchmark are available at \href{https://medagentsim.netlify.app/}.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22678v1,work introduce medagentsim opensource simulated clinical environment doctor patient measurement agent designed evaluate enhance llm performance dynamic diagnostic setting unlike prior approach framework requires doctor agent actively engage patient multiturn conversation requesting relevant medical examination eg temperature blood pressure ecg imaging result eg mri xray measurement agent mimic realworld diagnostic process additionally incorporate self improvement mechanism allow model iteratively refine diagnostic strategy enhance llm performance simulated setting integrating multiagent discussion chainofthought reasoning experiencebased knowledge retrieval facilitating progressive learning doctor agent interact patient also introduce evaluation benchmark assessing llm ability engage dynamic contextaware diagnostic interaction medagentsim fully automated also support usercontrolled mode enabling human interaction either doctor patient agent comprehensive evaluation various simulated diagnostic scenario demonstrate effectiveness approach code simulation tool benchmark available hrefhttpsmedagentsimnetlifyapp
2503.22676v1,TranSplat: Lighting-Consistent Cross-Scene Object Transfer with 3D Gaussian Splatting,"['Boyang', 'Yu', 'Yanlin Jin', 'Ashok Veeraraghavan', 'Akshat Dave', 'Guha Balakrishnan']","We present TranSplat, a 3D scene rendering algorithm that enables realistic cross-scene object transfer (from a source to a target scene) based on the Gaussian Splatting framework. Our approach addresses two critical challenges: (1) precise 3D object extraction from the source scene, and (2) faithful relighting of the transferred object in the target scene without explicit material property estimation. TranSplat fits a splatting model to the source scene, using 2D object masks to drive fine-grained 3D segmentation. Following user-guided insertion of the object into the target scene, along with automatic refinement of position and orientation, TranSplat derives per-Gaussian radiance transfer functions via spherical harmonic analysis to adapt the object's appearance to match the target scene's lighting environment. This relighting strategy does not require explicitly estimating physical scene properties such as BRDFs. Evaluated on several synthetic and real-world scenes and objects, TranSplat yields excellent 3D object extractions and relighting performance compared to recent baseline methods and visually convincing cross-scene object transfers. We conclude by discussing the limitations of the approach.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22676v1,present transplat 3d scene rendering algorithm enables realistic crossscene object transfer source target scene based gaussian splatting framework approach address two critical challenge 1 precise 3d object extraction source scene 2 faithful relighting transferred object target scene without explicit material property estimation transplat fit splatting model source scene using 2d object mask drive finegrained 3d segmentation following userguided insertion object target scene along automatic refinement position orientation transplat derives pergaussian radiance transfer function via spherical harmonic analysis adapt object appearance match target scene lighting environment relighting strategy require explicitly estimating physical scene property brdfs evaluated several synthetic realworld scene object transplat yield excellent 3d object extraction relighting performance compared recent baseline method visually convincing crossscene object transfer conclude discussing limitation approach
2503.22675v1,Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation,"['Jiakai Tang', 'Sunhao Dai', 'Teng Shi', 'Jun Xu', 'Xu Chen', 'Wen Chen', 'Wu Jian', 'Yuning Jiang']","Sequential Recommendation (SeqRec) aims to predict the next item by capturing sequential patterns from users' historical interactions, playing a crucial role in many real-world recommender systems. However, existing approaches predominantly adopt a direct forward computation paradigm, where the final hidden state of the sequence encoder serves as the user representation. We argue that this inference paradigm, due to its limited computational depth, struggles to model the complex evolving nature of user preferences and lacks a nuanced understanding of long-tail items, leading to suboptimal performance. To address this issue, we propose \textbf{ReaRec}, the first inference-time computing framework for recommender systems, which enhances user representations through implicit multi-step reasoning. Specifically, ReaRec autoregressively feeds the sequence's last hidden state into the sequential recommender while incorporating special reasoning position embeddings to decouple the original item encoding space from the multi-step reasoning space. Moreover, we introduce two lightweight reasoning-based learning methods, Ensemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to further effectively exploit ReaRec's reasoning potential. Extensive experiments on five public real-world datasets and different SeqRec architectures demonstrate the generality and effectiveness of our proposed ReaRec. Remarkably, post-hoc analyses reveal that ReaRec significantly elevates the performance ceiling of multiple sequential recommendation backbones by approximately 30\%-50\%. Thus, we believe this work can open a new and promising avenue for future research in inference-time computing for sequential recommendation.",2025-03-28,"['cs.IR', 'cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22675v1,sequential recommendation seqrec aim predict next item capturing sequential pattern user historical interaction playing crucial role many realworld recommender system however existing approach predominantly adopt direct forward computation paradigm final hidden state sequence encoder serf user representation argue inference paradigm due limited computational depth struggle model complex evolving nature user preference lack nuanced understanding longtail item leading suboptimal performance address issue propose textbfrearec first inferencetime computing framework recommender system enhances user representation implicit multistep reasoning specifically rearec autoregressively feed sequence last hidden state sequential recommender incorporating special reasoning position embeddings decouple original item encoding space multistep reasoning space moreover introduce two lightweight reasoningbased learning method ensemble reasoning learning erl progressive reasoning learning prl effectively exploit rearecs reasoning potential extensive experiment five public realworld datasets different seqrec architecture demonstrate generality effectiveness proposed rearec remarkably posthoc analysis reveal rearec significantly elevates performance ceiling multiple sequential recommendation backbone approximately 3050 thus believe work open new promising avenue future research inferencetime computing sequential recommendation
2503.22674v1,QuestBench: Can LLMs ask the right question to acquire information in reasoning tasks?,"['Belinda Z. Li', 'Been Kim', 'Zi Wang']","Recently, a large amount of work has focused on improving large language models' (LLMs') performance on reasoning benchmarks such as math and logic. However, past work has largely assumed that tasks are well-defined. In the real world, queries to LLMs are often underspecified, only solvable through acquiring missing information. We formalize this as a constraint satisfaction problem (CSP) with missing variable assignments. Using a special case of this formalism where only one necessary variable assignment is missing, we can rigorously evaluate an LLM's ability to identify the minimal necessary question to ask and quantify axes of difficulty levels for each problem. We present QuestBench, a set of underspecified reasoning tasks solvable by asking at most one question, which includes: (1) Logic-Q: Logical reasoning tasks with one missing proposition, (2) Planning-Q: PDDL planning problems with initial states that are partially-observed, (3) GSM-Q: Human-annotated grade school math problems with one missing variable assignment, and (4) GSME-Q: a version of GSM-Q where word problems are translated into equations by human annotators. The LLM is tasked with selecting the correct clarification question(s) from a list of options. While state-of-the-art models excel at GSM-Q and GSME-Q, their accuracy is only 40-50% on Logic-Q and Planning-Q. Analysis demonstrates that the ability to solve well-specified reasoning problems may not be sufficient for success on our benchmark: models have difficulty identifying the right question to ask, even when they can solve the fully specified version of the problem. Furthermore, in the Planning-Q domain, LLMs tend not to hedge, even when explicitly presented with the option to predict ``not sure.'' This highlights the need for deeper investigation into models' information acquisition capabilities.",2025-03-28,"['cs.AI', 'cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22674v1,recently large amount work focused improving large language model llm performance reasoning benchmark math logic however past work largely assumed task welldefined real world query llm often underspecified solvable acquiring missing information formalize constraint satisfaction problem csp missing variable assignment using special case formalism one necessary variable assignment missing rigorously evaluate llm ability identify minimal necessary question ask quantify ax difficulty level problem present questbench set underspecified reasoning task solvable asking one question includes 1 logicq logical reasoning task one missing proposition 2 planningq pddl planning problem initial state partiallyobserved 3 gsmq humanannotated grade school math problem one missing variable assignment 4 gsmeq version gsmq word problem translated equation human annotator llm tasked selecting correct clarification question list option stateoftheart model excel gsmq gsmeq accuracy 4050 logicq planningq analysis demonstrates ability solve wellspecified reasoning problem may sufficient success benchmark model difficulty identifying right question ask even solve fully specified version problem furthermore planningq domain llm tend hedge even explicitly presented option predict sure highlight need deeper investigation model information acquisition capability
2503.22673v1,ActionStudio: A Lightweight Framework for Data and Training of Action Models,"['Jianguo Zhang', 'Thai Hoang', 'Ming Zhu', 'Zuxin Liu', 'Shiyu Wang', 'Tulika Awalgaonkar', 'Akshara Prabhakar', 'Haolin Chen', 'Weiran Yao', 'Zhiwei Liu', 'Juntao Tan', 'Juan Carlos Niebles', 'Shelby Heinecke', 'Huan Wang', 'Silvio Savarese', 'Caiming Xiong']","Action models are essential for enabling autonomous agents to perform complex tasks. However, training large action models remains challenging due to the diversity of agent environments and the complexity of agentic data. Despite growing interest, existing infrastructure provides limited support for scalable, agent-specific fine-tuning. We present ActionStudio, a lightweight and extensible data and training framework designed for action models. ActionStudio unifies heterogeneous agent trajectories through a standardized format, supports diverse training paradigms including LoRA, full fine-tuning, and distributed setups, and integrates robust preprocessing and verification tools. We validate its effectiveness across both public and realistic industry benchmarks, demonstrating strong performance and practical scalability. We open-sourced code and data at https://github.com/SalesforceAIResearch/xLAM to facilitate research in the community.",2025-03-28,"['cs.AI', 'cs.CL']",http://arxiv.org/pdf/2503.22673v1,action model essential enabling autonomous agent perform complex task however training large action model remains challenging due diversity agent environment complexity agentic data despite growing interest existing infrastructure provides limited support scalable agentspecific finetuning present actionstudio lightweight extensible data training framework designed action model actionstudio unifies heterogeneous agent trajectory standardized format support diverse training paradigm including lora full finetuning distributed setup integrates robust preprocessing verification tool validate effectiveness across public realistic industry benchmark demonstrating strong performance practical scalability opensourced code data httpsgithubcomsalesforceairesearchxlam facilitate research community
2503.22672v1,Exploring the Effectiveness of Multi-stage Fine-tuning for Cross-encoder Re-rankers,"['Francesca Pezzuti', 'Sean MacAvaney', 'Nicola Tonellotto']","State-of-the-art cross-encoders can be fine-tuned to be highly effective in passage re-ranking. The typical fine-tuning process of cross-encoders as re-rankers requires large amounts of manually labelled data, a contrastive learning objective, and a set of heuristically sampled negatives. An alternative recent approach for fine-tuning instead involves teaching the model to mimic the rankings of a highly effective large language model using a distillation objective. These fine-tuning strategies can be applied either individually, or in sequence. In this work, we systematically investigate the effectiveness of point-wise cross-encoders when fine-tuned independently in a single stage, or sequentially in two stages. Our experiments show that the effectiveness of point-wise cross-encoders fine-tuned using contrastive learning is indeed on par with that of models fine-tuned with multi-stage approaches. Code is available for reproduction at https://github.com/fpezzuti/multistage-finetuning.",2025-03-28,"['cs.IR', 'cs.AI']",http://arxiv.org/pdf/2503.22672v1,stateoftheart crossencoders finetuned highly effective passage reranking typical finetuning process crossencoders rerankers requires large amount manually labelled data contrastive learning objective set heuristically sampled negative alternative recent approach finetuning instead involves teaching model mimic ranking highly effective large language model using distillation objective finetuning strategy applied either individually sequence work systematically investigate effectiveness pointwise crossencoders finetuned independently single stage sequentially two stage experiment show effectiveness pointwise crossencoders finetuned using contrastive learning indeed par model finetuned multistage approach code available reproduction httpsgithubcomfpezzutimultistagefinetuning
2503.22669v1,"Light Tree Covers, Routing, and Path-Reporting Oracles via Spanning Tree Covers in Doubling Graphs","['Hsien-Chih Chang', 'Jonathan Conroy', 'Hung Le', 'Shay Solomon', 'Cuong Than']","A $(1+\varepsilon)$-stretch tree cover of an edge-weighted $n$-vertex graph $G$ is a collection of trees, where every pair of vertices has a $(1+\varepsilon)$-stretch path in one of the trees. The celebrated Dumbbell Theorem by Arya et. al. [STOC'95] states that any set of $n$ points in $d$-dimensional Euclidean space admits a $(1+\varepsilon)$-stretch tree cover with a constant number of trees, where the constant depends on $\varepsilon$ and the dimension $d$. This result was generalized for arbitrary doubling metrics by Bartal et. al. [ICALP'19]. While the total number of edges in the tree covers of Arya et. al. and Bartal et. al. is $O(n)$, all known tree cover constructions incur a total lightness of $\Omega(\log n)$; whether one can get a tree cover of constant lightness has remained a longstanding open question, even for 2-dimensional point sets.   In this work we resolve this fundamental question in the affirmative, as a direct corollary of a new construction of $(1+\varepsilon)$-stretch spanning tree cover for doubling graphs; in a spanning tree cover, every tree may only use edges of the input graph rather than the corresponding metric. To the best of our knowledge, this is the first constant-stretch spanning tree cover construction (let alone for $(1+\varepsilon)$-stretch) with a constant number of trees, for any nontrivial family of graphs.   Concrete applications of our spanning tree cover include a $(1+\varepsilon)$-stretch light tree cover, a compact $(1+\varepsilon)$-stretch routing scheme in the labeled model, and a $(1+\varepsilon)$-stretch path-reporting distance oracle, for doubling graphs. [...]",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22669v1,1varepsilonstretch tree cover edgeweighted nvertex graph g collection tree every pair vertex 1varepsilonstretch path one tree celebrated dumbbell theorem arya et al stoc95 state set n point ddimensional euclidean space admits 1varepsilonstretch tree cover constant number tree constant depends varepsilon dimension result generalized arbitrary doubling metric bartal et al icalp19 total number edge tree cover arya et al bartal et al known tree cover construction incur total lightness omegalog n whether one get tree cover constant lightness remained longstanding open question even 2dimensional point set work resolve fundamental question affirmative direct corollary new construction 1varepsilonstretch spanning tree cover doubling graph spanning tree cover every tree may use edge input graph rather corresponding metric best knowledge first constantstretch spanning tree cover construction let alone 1varepsilonstretch constant number tree nontrivial family graph concrete application spanning tree cover include 1varepsilonstretch light tree cover compact 1varepsilonstretch routing scheme labeled model 1varepsilonstretch pathreporting distance oracle doubling graph
2503.22668v1,Understanding Co-speech Gestures in-the-wild,"['Sindhu B Hegde', 'K R Prajwal', 'Taein Kwon', 'Andrew Zisserman']","Co-speech gestures play a vital role in non-verbal communication. In this paper, we introduce a new framework for co-speech gesture understanding in the wild. Specifically, we propose three new tasks and benchmarks to evaluate a model's capability to comprehend gesture-text-speech associations: (i) gesture-based retrieval, (ii) gestured word spotting, and (iii) active speaker detection using gestures. We present a new approach that learns a tri-modal speech-text-video-gesture representation to solve these tasks. By leveraging a combination of global phrase contrastive loss and local gesture-word coupling loss, we demonstrate that a strong gesture representation can be learned in a weakly supervised manner from videos in the wild. Our learned representations outperform previous methods, including large vision-language models (VLMs), across all three tasks. Further analysis reveals that speech and text modalities capture distinct gesture-related signals, underscoring the advantages of learning a shared tri-modal embedding space. The dataset, model, and code are available at: https://www.robots.ox.ac.uk/~vgg/research/jegal",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22668v1,cospeech gesture play vital role nonverbal communication paper introduce new framework cospeech gesture understanding wild specifically propose three new task benchmark evaluate model capability comprehend gesturetextspeech association gesturebased retrieval ii gestured word spotting iii active speaker detection using gesture present new approach learns trimodal speechtextvideogesture representation solve task leveraging combination global phrase contrastive loss local gestureword coupling loss demonstrate strong gesture representation learned weakly supervised manner video wild learned representation outperform previous method including large visionlanguage model vlms across three task analysis reveals speech text modality capture distinct gesturerelated signal underscoring advantage learning shared trimodal embedding space dataset model code available httpswwwrobotsoxacukvggresearchjegal
2503.22663v1,NetSSM: Multi-Flow and State-Aware Network Trace Generation using State-Space Models,"['Andrew Chu', 'Xi Jiang', 'Shinan Liu', 'Arjun Bhagoji', 'Francesco Bronzino', 'Paul Schmitt', 'Nick Feamster']","Access to raw network traffic data is essential for many computer networking tasks, from traffic modeling to performance evaluation. Unfortunately, this data is scarce due to high collection costs and governance rules. Previous efforts explore this challenge by generating synthetic network data, but fail to reliably handle multi-flow sessions, struggle to reason about stateful communication in moderate to long-duration network sessions, and lack robust evaluations tied to real-world utility. We propose a new method based on state-space models called NetSSM that generates raw network traffic at the packet-level granularity. Our approach captures interactions between multiple, interleaved flows -- an objective unexplored in prior work -- and effectively reasons about flow-state in sessions to capture traffic characteristics. NetSSM accomplishes this by learning from and producing traces 8x and 78x longer than existing transformer-based approaches. Evaluation results show that our method generates high-fidelity traces that outperform prior efforts in existing benchmarks. We also find that NetSSM's traces have high semantic similarity to real network data regarding compliance with standard protocol requirements and flow and session-level traffic characteristics.",2025-03-28,['cs.NI'],http://arxiv.org/pdf/2503.22663v1,access raw network traffic data essential many computer networking task traffic modeling performance evaluation unfortunately data scarce due high collection cost governance rule previous effort explore challenge generating synthetic network data fail reliably handle multiflow session struggle reason stateful communication moderate longduration network session lack robust evaluation tied realworld utility propose new method based statespace model called netssm generates raw network traffic packetlevel granularity approach capture interaction multiple interleaved flow objective unexplored prior work effectively reason flowstate session capture traffic characteristic netssm accomplishes learning producing trace 8x 78x longer existing transformerbased approach evaluation result show method generates highfidelity trace outperform prior effort existing benchmark also find netssms trace high semantic similarity real network data regarding compliance standard protocol requirement flow sessionlevel traffic characteristic
2503.22660v1,Verifying Nonlinear Neural Feedback Systems using Polyhedral Enclosures,"['Samuel I. Akinwande', 'Chelsea Sidrane', 'Mykel J. Kochenderfer', 'Clark Barrett']","As dynamical systems equipped with neural network controllers (neural feedback systems) become increasingly prevalent, it is critical to develop methods to ensure their safe operation. Verifying safety requires extending control theoretic analysis methods to these systems. Although existing techniques can efficiently handle linear neural feedback systems, relatively few scalable methods address the nonlinear case. We propose a novel algorithm for forward reachability analysis of nonlinear neural feedback systems. The approach leverages the structure of the nonlinear transition functions of the systems to compute tight polyhedral enclosures (i.e., abstractions). These enclosures, combined with the neural controller, are then encoded as a mixed-integer linear program (MILP). Optimizing this MILP yields a sound over-approximation of the forward-reachable set. We evaluate our algorithm on representative benchmarks and demonstrate an order of magnitude improvement over the current state of the art.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22660v1,dynamical system equipped neural network controller neural feedback system become increasingly prevalent critical develop method ensure safe operation verifying safety requires extending control theoretic analysis method system although existing technique efficiently handle linear neural feedback system relatively scalable method address nonlinear case propose novel algorithm forward reachability analysis nonlinear neural feedback system approach leverage structure nonlinear transition function system compute tight polyhedral enclosure ie abstraction enclosure combined neural controller encoded mixedinteger linear program milp optimizing milp yield sound overapproximation forwardreachable set evaluate algorithm representative benchmark demonstrate order magnitude improvement current state art
2503.22658v1,Evaluation of Machine-generated Biomedical Images via A Tally-based Similarity Measure,"['Frank J. Brooks', 'Rucha Deshpande']","Super-resolution, in-painting, whole-image generation, unpaired style-transfer, and network-constrained image reconstruction each include an aspect of machine-learned image synthesis where the actual ground truth is not known at time of use. It is generally difficult to quantitatively and authoritatively evaluate the quality of synthetic images; however, in mission-critical biomedical scenarios robust evaluation is paramount. In this work, all practical image-to-image comparisons really are relative qualifications, not absolute difference quantifications; and, therefore, meaningful evaluation of generated image quality can be accomplished using the Tversky Index, which is a well-established measure for assessing perceptual similarity. This evaluation procedure is developed and then demonstrated using multiple image data sets, both real and simulated. The main result is that when the subjectivity and intrinsic deficiencies of any feature-encoding choice are put upfront, Tversky's method leads to intuitive results, whereas traditional methods based on summarizing distances in deep feature spaces do not.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22658v1,superresolution inpainting wholeimage generation unpaired styletransfer networkconstrained image reconstruction include aspect machinelearned image synthesis actual ground truth known time use generally difficult quantitatively authoritatively evaluate quality synthetic image however missioncritical biomedical scenario robust evaluation paramount work practical imagetoimage comparison really relative qualification absolute difference quantification therefore meaningful evaluation generated image quality accomplished using tversky index wellestablished measure assessing perceptual similarity evaluation procedure developed demonstrated using multiple image data set real simulated main result subjectivity intrinsic deficiency featureencoding choice put upfront tverskys method lead intuitive result whereas traditional method based summarizing distance deep feature space
2503.22656v1,Differential equation quantum solvers: engineering measurements to reduce cost,"['Annie Paine', 'Casper Gyurik', 'Antonio Andrea Gentile']","Quantum computers have been proposed as a solution for efficiently solving non-linear differential equations (DEs), a fundamental task across diverse technological and scientific domains. However, a crucial milestone in this regard is to design protocols that are hardware-aware, making efficient use of limited available quantum resources. We focus here on promising variational methods derived from scientific machine learning: differentiable quantum circuits (DQC), addressing specifically their cost in number of circuit evaluations. Reducing the number of quantum circuit evaluations is particularly valuable in hybrid quantum/classical protocols, where the time required to interface and run quantum hardware at each cycle can impact the total wall-time much more than relatively inexpensive classical post-processing overhead. Here, we propose and test two sample-efficient protocols for solving non-linear DEs, achieving exponential savings in quantum circuit evaluations. These protocols are based on redesigning the extraction of information from DQC in a ``measure-first"" approach, by introducing engineered cost operators similar to the randomized-measurement toolbox (i.e. classical shadows). In benchmark simulations on one and two-dimensional DEs, we report up to $\sim$ 100 fold reductions in circuit evaluations. Our protocols thus hold the promise to unlock larger and more challenging non-linear differential equation demonstrations with existing quantum hardware.",2025-03-28,"['quant-ph', 'cs.LG']",http://arxiv.org/pdf/2503.22656v1,quantum computer proposed solution efficiently solving nonlinear differential equation de fundamental task across diverse technological scientific domain however crucial milestone regard design protocol hardwareaware making efficient use limited available quantum resource focus promising variational method derived scientific machine learning differentiable quantum circuit dqc addressing specifically cost number circuit evaluation reducing number quantum circuit evaluation particularly valuable hybrid quantumclassical protocol time required interface run quantum hardware cycle impact total walltime much relatively inexpensive classical postprocessing overhead propose test two sampleefficient protocol solving nonlinear de achieving exponential saving quantum circuit evaluation protocol based redesigning extraction information dqc measurefirst approach introducing engineered cost operator similar randomizedmeasurement toolbox ie classical shadow benchmark simulation one twodimensional de report sim 100 fold reduction circuit evaluation protocol thus hold promise unlock larger challenging nonlinear differential equation demonstration existing quantum hardware
2503.22655v1,Unicorn: Text-Only Data Synthesis for Vision Language Model Training,"['Xiaomin Yu', 'Pengxiang Ding', 'Wenjie Zhang', 'Siteng Huang', 'Songyang Gao', 'Chengwei Qin', 'Kejian Wu', 'Zhaoxin Fan', 'Ziyue Qiao', 'Donglin Wang']","Training vision-language models (VLMs) typically requires large-scale, high-quality image-text pairs, but collecting or synthesizing such data is costly. In contrast, text data is abundant and inexpensive, prompting the question: can high-quality multimodal training data be synthesized purely from text? To tackle this, we propose a cross-integrated three-stage multimodal data synthesis framework, which generates two datasets: Unicorn-1.2M and Unicorn-471K-Instruction. In Stage 1: Diverse Caption Data Synthesis, we construct 1.2M semantically diverse high-quality captions by expanding sparse caption seeds using large language models (LLMs). In Stage 2: Instruction-Tuning Data Generation, we further process 471K captions into multi-turn instruction-tuning tasks to support complex reasoning. Finally, in Stage 3: Modality Representation Transfer, these textual captions representations are transformed into visual representations, resulting in diverse synthetic image representations. This three-stage process enables us to construct Unicorn-1.2M for pretraining and Unicorn-471K-Instruction for instruction-tuning, without relying on real images. By eliminating the dependency on real images while maintaining data quality and diversity, our framework offers a cost-effective and scalable solution for VLMs training. Code is available at https://github.com/Yu-xm/Unicorn.git.",2025-03-28,"['cs.AI', 'cs.CV', 'cs.MM']",http://arxiv.org/pdf/2503.22655v1,training visionlanguage model vlms typically requires largescale highquality imagetext pair collecting synthesizing data costly contrast text data abundant inexpensive prompting question highquality multimodal training data synthesized purely text tackle propose crossintegrated threestage multimodal data synthesis framework generates two datasets unicorn12m unicorn471kinstruction stage 1 diverse caption data synthesis construct 12m semantically diverse highquality caption expanding sparse caption seed using large language model llm stage 2 instructiontuning data generation process 471k caption multiturn instructiontuning task support complex reasoning finally stage 3 modality representation transfer textual caption representation transformed visual representation resulting diverse synthetic image representation threestage process enables u construct unicorn12m pretraining unicorn471kinstruction instructiontuning without relying real image eliminating dependency real image maintaining data quality diversity framework offer costeffective scalable solution vlms training code available httpsgithubcomyuxmunicorngit
2503.22653v1,Tropical Bisectors and Carlini-Wagner Attacks,"['Gillian Grindstaff', 'Julia Lindberg', 'Daniela Schkoda', 'Miruna-Stefana Sorea', 'Ruriko Yoshida']","Pasque et al. showed that using a tropical symmetric metric as an activation function in the last layer can improve the robustness of convolutional neural networks (CNNs) against state-of-the-art attacks, including the Carlini-Wagner attack. This improvement occurs when the attacks are not specifically adapted to the non-differentiability of the tropical layer. Moreover, they showed that the decision boundary of a tropical CNN is defined by tropical bisectors. In this paper, we explore the combinatorics of tropical bisectors and analyze how the tropical embedding layer enhances robustness against Carlini-Wagner attacks. We prove an upper bound on the number of linear segments the decision boundary of a tropical CNN can have. We then propose a refined version of the Carlini-Wagner attack, specifically tailored for the tropical architecture. Computational experiments with MNIST and LeNet5 showcase our attacks improved success rate.",2025-03-28,"['cs.LG', 'math.AG', 'math.CO', 'math.MG', 'math.OC', '14T90, 52B12, 68T07']",http://arxiv.org/pdf/2503.22653v1,pasque et al showed using tropical symmetric metric activation function last layer improve robustness convolutional neural network cnns stateoftheart attack including carliniwagner attack improvement occurs attack specifically adapted nondifferentiability tropical layer moreover showed decision boundary tropical cnn defined tropical bisectors paper explore combinatorics tropical bisectors analyze tropical embedding layer enhances robustness carliniwagner attack prove upper bound number linear segment decision boundary tropical cnn propose refined version carliniwagner attack specifically tailored tropical architecture computational experiment mnist lenet5 showcase attack improved success rate
2503.22652v1,Residual-based Chebyshev filtered subspace iteration for sparse Hermitian eigenvalue problems tolerant to inexact matrix-vector products,"['Nikhil Kodali', 'Kartick Ramakrishnan', 'Phani Motamarri']","Chebyshev Filtered Subspace Iteration (ChFSI) has been widely adopted for computing a small subset of extreme eigenvalues in large sparse matrices. This work introduces a residual-based reformulation of ChFSI, referred to as R-ChFSI, designed to accommodate inexact matrix-vector products while maintaining robust convergence properties. By reformulating the traditional Chebyshev recurrence to operate on residuals rather than eigenvector estimates, the R-ChFSI approach effectively suppresses the errors made in matrix-vector products, improving the convergence behaviour for both standard and generalized eigenproblems. This ability of R-ChFSI to be tolerant to inexact matrix-vector products allows one to incorporate approximate inverses for large-scale generalized eigenproblems, making the method particularly attractive where exact matrix factorizations or iterative methods become computationally expensive for evaluating inverses. It also allows us to compute the matrix-vector products in lower-precision arithmetic allowing us to leverage modern hardware accelerators. Through extensive benchmarking, we demonstrate that R-ChFSI achieves desired residual tolerances while leveraging low-precision arithmetic. For problems with millions of degrees of freedom and thousands of eigenvalues, R-ChFSI attains final residual norms in the range of 10$^{-12}$ to 10$^{-14}$, even with FP32 and TF32 arithmetic, significantly outperforming standard ChFSI in similar settings. In generalized eigenproblems, where approximate inverses are used, R-ChFSI achieves residual tolerances up to ten orders of magnitude lower, demonstrating its robustness to approximation errors. Finally, R-ChFSI provides a scalable and computationally efficient alternative for solving large-scale eigenproblems in high-performance computing environments.",2025-03-28,"['physics.comp-ph', 'cs.NA', 'math.NA']",http://arxiv.org/pdf/2503.22652v1,chebyshev filtered subspace iteration chfsi widely adopted computing small subset extreme eigenvalue large sparse matrix work introduces residualbased reformulation chfsi referred rchfsi designed accommodate inexact matrixvector product maintaining robust convergence property reformulating traditional chebyshev recurrence operate residual rather eigenvector estimate rchfsi approach effectively suppresses error made matrixvector product improving convergence behaviour standard generalized eigenproblems ability rchfsi tolerant inexact matrixvector product allows one incorporate approximate inverse largescale generalized eigenproblems making method particularly attractive exact matrix factorization iterative method become computationally expensive evaluating inverse also allows u compute matrixvector product lowerprecision arithmetic allowing u leverage modern hardware accelerator extensive benchmarking demonstrate rchfsi achieves desired residual tolerance leveraging lowprecision arithmetic problem million degree freedom thousand eigenvalue rchfsi attains final residual norm range 1012 1014 even fp32 tf32 arithmetic significantly outperforming standard chfsi similar setting generalized eigenproblems approximate inverse used rchfsi achieves residual tolerance ten order magnitude lower demonstrating robustness approximation error finally rchfsi provides scalable computationally efficient alternative solving largescale eigenproblems highperformance computing environment
2503.22651v1,Optimal Locality and Parameter Tradeoffs for Subsystem Codes,"['Samuel Dai', 'Ray Li', 'Eugene Tang']","We study the tradeoffs between the locality and parameters of subsystem codes. We prove lower bounds on both the number and lengths of interactions in any $D$-dimensional embedding of a subsystem code. Specifically, we show that any embedding of a subsystem code with parameters $[[n,k,d]]$ into $\mathbb{R}^D$ must have at least $M^*$ interactions of length at least $\ell^*$, where   \[ M^* = \Omega(\max(k,d)), \quad\text{and}\quad \ell^* = \Omega\bigg(\max\bigg(\frac{d}{n^\frac{D-1}{D}}, \bigg(\frac{kd^\frac{1}{D-1}}{n}\bigg)^\frac{D-1}{D}\bigg)\bigg). \] We also give tradeoffs between the locality and parameters of commuting projector codes in $D$-dimensions, generalizing a result of Dai and Li. We provide explicit constructions of embedded codes that show our bounds are optimal in both the interaction count and interaction length.",2025-03-28,"['quant-ph', 'cs.IT', 'math.IT']",http://arxiv.org/pdf/2503.22651v1,study tradeoff locality parameter subsystem code prove lower bound number length interaction ddimensional embedding subsystem code specifically show embedding subsystem code parameter nkd mathbbrd must least interaction length least ell omegamaxkd quadtextandquad ell omegabiggmaxbiggfracdnfracd1d biggfrackdfrac1d1nbiggfracd1dbiggbigg also give tradeoff locality parameter commuting projector code ddimensions generalizing result dai li provide explicit construction embedded code show bound optimal interaction count interaction length
2503.22650v1,Explicit non-free tensors,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Free tensors are tensors which, after a change of bases, have free support: any two distinct elements of its support differ in at least two coordinates. They play a distinguished role in the theory of bilinear complexity, in particular in Strassen's duality theory for asymptotic rank. Within the context of quantum information theory, where tensors are interpreted as multiparticle quantum states, freeness corresponds to a type of multiparticle Schmidt decomposition. In particular, if a state is free in a given basis, the reduced density matrices are diagonal. Although generic tensors in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$ are non-free for $n \geq 4$ by parameter counting, no explicit non-free tensors were known until now. We solve this hay in a haystack problem by constructing explicit tensors that are non-free for every $n \geq 3$. In particular, this establishes that non-free tensors exist in $\mathbb{C}^n \otimes \mathbb{C}^n \otimes \mathbb{C}^n$, where they are not generic.   To establish non-freeness, we use results from geometric invariant theory and the theory of moment polytopes. In particular, we show that if a tensor $T$ is free, then there is a tensor $S$ in the GL-orbit closure of $T$, whose support is free and whose moment map image is the minimum-norm point of the moment polytope of $T$. This implies a reduction for checking non-freeness from arbitrary basis changes of $T$ to unitary basis changes of $S$. The unitary equivariance of the moment map can then be combined with the fact that tensors with free support have diagonal moment map image, in order to further restrict the set of relevant basis changes.",2025-03-28,"['math.AG', 'cs.CC', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24, 53D25']",http://arxiv.org/pdf/2503.22650v1,free tensor tensor change base free support two distinct element support differ least two coordinate play distinguished role theory bilinear complexity particular strassens duality theory asymptotic rank within context quantum information theory tensor interpreted multiparticle quantum state freeness corresponds type multiparticle schmidt decomposition particular state free given basis reduced density matrix diagonal although generic tensor mathbbcn otimes mathbbcn otimes mathbbcn nonfree n geq 4 parameter counting explicit nonfree tensor known solve hay haystack problem constructing explicit tensor nonfree every n geq 3 particular establishes nonfree tensor exist mathbbcn otimes mathbbcn otimes mathbbcn generic establish nonfreeness use result geometric invariant theory theory moment polytopes particular show tensor free tensor glorbit closure whose support free whose moment map image minimumnorm point moment polytope implies reduction checking nonfreeness arbitrary basis change unitary basis change unitary equivariance moment map combined fact tensor free support diagonal moment map image order restrict set relevant basis change
2503.22646v1,Finding Unknown Unknowns using Cyber-Physical System Simulators (Extended Report),"['Semaan Douglas Wehbe', 'Stanley Bak']","Simulation-based approaches are among the most practical means to search for safety violations, bugs, and other unexpected events in cyber-physical systems (CPS). Where existing approaches search for simulations violating a formal specification or maximizing a notion of coverage, in this work we propose a new goal for testing: to discover unknown rare behaviors by examining discrete mode sequences. We assume a CPS simulator outputs mode information, and strive to explore the sequences of modes produced by varying the initial state or time-varying uncertainties. We hypothesize that rare mode sequences are often the most interesting to a designer, and we develop two accelerated sampling algorithms that speed up the process of finding such sequences. We evaluate our approach on several benchmarks, ranging from synthetic examples to Simulink diagrams of a CPS, demonstrating in some cases a speedup of over 100x compared with a random sampling strategy.",2025-03-28,"['eess.SY', 'cs.NA', 'cs.SY', 'math.NA']",http://arxiv.org/pdf/2503.22646v1,simulationbased approach among practical mean search safety violation bug unexpected event cyberphysical system cps existing approach search simulation violating formal specification maximizing notion coverage work propose new goal testing discover unknown rare behavior examining discrete mode sequence assume cps simulator output mode information strive explore sequence mode produced varying initial state timevarying uncertainty hypothesize rare mode sequence often interesting designer develop two accelerated sampling algorithm speed process finding sequence evaluate approach several benchmark ranging synthetic example simulink diagram cps demonstrating case speedup 100x compared random sampling strategy
2503.22645v1,A Performance Analysis of Task Scheduling for UQ Workflows on HPC Systems,"['Chung Ming Loi', 'Anne Reinarz', 'Mikkel Lykkegaard', 'William Hornsby', 'James Buchanan', 'Linus Seelinger']","Uncertainty Quantification (UQ) workloads are becoming increasingly common in science and engineering. They involve the submission of thousands or even millions of similar tasks with potentially unpredictable runtimes, where the total number is usually not known a priori. A static one-size-fits-all batch script would likely lead to suboptimal scheduling, and native schedulers installed on High Performance Computing (HPC) systems such as SLURM often struggle to efficiently handle such workloads. In this paper, we introduce a new load balancing approach suitable for UQ workflows. To demonstrate its efficiency in a real-world setting, we focus on the GS2 gyrokinetic plasma turbulence simulator. Individual simulations can be computationally demanding, with runtimes varying significantly-from minutes to hours-depending on the high-dimensional input parameters. Our approach uses UQ and Modelling Bridge, which offers a language-agnostic interface to a simulation model, combined with HyperQueue which works alongside the native scheduler. In particular, deploying this framework on HPC systems does not require system-level changes. We benchmark our proposed framework against a standalone SLURM approach using GS2 and a Gaussian Process surrogate thereof. Our results demonstrate a reduction in scheduling overhead by up to three orders of magnitude and a maximum reduction of 38% in CPU time for long-running simulations compared to the naive SLURM approach, while making no assumptions about the job submission patterns inherent to UQ workflows.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22645v1,uncertainty quantification uq workload becoming increasingly common science engineering involve submission thousand even million similar task potentially unpredictable runtimes total number usually known priori static onesizefitsall batch script would likely lead suboptimal scheduling native scheduler installed high performance computing hpc system slurm often struggle efficiently handle workload paper introduce new load balancing approach suitable uq workflow demonstrate efficiency realworld setting focus gs2 gyrokinetic plasma turbulence simulator individual simulation computationally demanding runtimes varying significantlyfrom minute hoursdepending highdimensional input parameter approach us uq modelling bridge offer languageagnostic interface simulation model combined hyperqueue work alongside native scheduler particular deploying framework hpc system require systemlevel change benchmark proposed framework standalone slurm approach using gs2 gaussian process surrogate thereof result demonstrate reduction scheduling overhead three order magnitude maximum reduction 38 cpu time longrunning simulation compared naive slurm approach making assumption job submission pattern inherent uq workflow
2503.22643v1,Hiding Latencies in Network-Based Image Loading for Deep Learning,"['Francesco Versaci', 'Giovanni Busonera']","In the last decades, the computational power of GPUs has grown exponentially, allowing current deep learning (DL) applications to handle increasingly large amounts of data at a progressively higher throughput. However, network and storage latencies cannot decrease at a similar pace due to physical constraints, leading to data stalls, and creating a bottleneck for DL tasks. Additionally, managing vast quantities of data and their associated metadata has proven challenging, hampering and slowing the productivity of data scientists. Moreover, existing data loaders have limited network support, necessitating, for maximum performance, that data be stored on local filesystems close to the GPUs, overloading the storage of computing nodes.   In this paper we propose a strategy, aimed at DL image applications, to address these challenges by: storing data and metadata in fast, scalable NoSQL databases; connecting the databases to state-of-the-art loaders for DL frameworks; enabling high-throughput data loading over high-latency networks through our out-of-order, incremental prefetching techniques. To evaluate our approach, we showcase our implementation and assess its data loading capabilities through local, medium and high-latency (intercontinental) experiments.",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22643v1,last decade computational power gpus grown exponentially allowing current deep learning dl application handle increasingly large amount data progressively higher throughput however network storage latency decrease similar pace due physical constraint leading data stall creating bottleneck dl task additionally managing vast quantity data associated metadata proven challenging hampering slowing productivity data scientist moreover existing data loader limited network support necessitating maximum performance data stored local filesystems close gpus overloading storage computing node paper propose strategy aimed dl image application address challenge storing data metadata fast scalable nosql database connecting database stateoftheart loader dl framework enabling highthroughput data loading highlatency network outoforder incremental prefetching technique evaluate approach showcase implementation ass data loading capability local medium highlatency intercontinental experiment
2503.22641v1,QuCheck: A Property-based Testing Framework for Quantum Programs in Qiskit,"['Gabriel Pontolillo', 'Mohammad Reza Mousavi', 'Marek Grzesiuk']","Property-based testing has been previously proposed for quantum programs in Q# with QSharpCheck; however, this implementation was limited in functionality, lacked extensibility, and was evaluated on a narrow range of programs using a single property. To address these limitations, we propose QuCheck, an enhanced property-based testing framework in Qiskit. By leveraging Qiskit and the broader Python ecosystem, QuCheck facilitates property construction, introduces flexible input generators and assertions, and supports expressive preconditions. We assessed its effectiveness through mutation analysis on five quantum programs (2-10 qubits), varying the number of properties, inputs, and measurement shots to assess their impact on fault detection and demonstrate the effectiveness of property-based testing across a range of conditions. Results show a strong positive correlation between the mutation score (a measure of fault detection) and number of properties evaluated, with a moderate negative correlation between the false positive rate and number of measurement shots. Among the most thorough test configurations, those evaluating three properties achieved a mean mutation score ranging from 0.90 to 0.92 across all five algorithms, with the false positive rate between 0 and 0.04. QuCheck identified 36.0% more faults than QSharpCheck, with execution time reduced by 81.1%, despite one false positive. These findings underscore the viability of property-based testing for verifying quantum systems.",2025-03-28,"['quant-ph', 'cs.SE']",http://arxiv.org/pdf/2503.22641v1,propertybased testing previously proposed quantum program q qsharpcheck however implementation limited functionality lacked extensibility evaluated narrow range program using single property address limitation propose qucheck enhanced propertybased testing framework qiskit leveraging qiskit broader python ecosystem qucheck facilitates property construction introduces flexible input generator assertion support expressive precondition assessed effectiveness mutation analysis five quantum program 210 qubits varying number property input measurement shot ass impact fault detection demonstrate effectiveness propertybased testing across range condition result show strong positive correlation mutation score measure fault detection number property evaluated moderate negative correlation false positive rate number measurement shot among thorough test configuration evaluating three property achieved mean mutation score ranging 090 092 across five algorithm false positive rate 0 004 qucheck identified 360 fault qsharpcheck execution time reduced 811 despite one false positive finding underscore viability propertybased testing verifying quantum system
2503.22639v1,Worst-Case Analysis of Decoupled Policies for Multi-Location Inventory Control Problems,"['Yohan John', 'Vade Shah', 'James A. Preiss', 'Mahnoosh Alizadeh', 'Jason R. Marden']","The difference in performance between centralized and decentralized control strategies crucially informs design choices in real-world control systems. Although computing and executing centralized control algorithms is often more costly than decentralized methods, their performance enhancements may far outweigh these costs. In this work, we study the value of centralization within the context of the well-known inventory control problem, where a planner seeks to identify optimal inventory levels that meet stochastic demand while minimizing ordering costs, holding costs, and shortage costs. We consider multilocation systems in which the inventories are coupled through a single ordering channel and the associated ordering cost function belongs to one of two classes of nonlinear cost functions that often arise in practical settings. For each of these classes, we derive constant-factor competitive ratios between the optimal coupled and decoupled policies and show they are almost tight. We then demonstrate that online algorithms also achieve tight competitive ratios for this problem. We conclude with numerical simulations that validate these results.",2025-03-28,"['math.OC', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22639v1,difference performance centralized decentralized control strategy crucially informs design choice realworld control system although computing executing centralized control algorithm often costly decentralized method performance enhancement may far outweigh cost work study value centralization within context wellknown inventory control problem planner seek identify optimal inventory level meet stochastic demand minimizing ordering cost holding cost shortage cost consider multilocation system inventory coupled single ordering channel associated ordering cost function belongs one two class nonlinear cost function often arise practical setting class derive constantfactor competitive ratio optimal coupled decoupled policy show almost tight demonstrate online algorithm also achieve tight competitive ratio problem conclude numerical simulation validate result
2503.22634v1,Empirical Analysis of Sim-and-Real Cotraining Of Diffusion Policies For Planar Pushing from Pixels,"['Adam Wei', 'Abhinav Agarwal', 'Boyuan Chen', 'Rohan Bosworth', 'Nicholas Pfaff', 'Russ Tedrake']","In imitation learning for robotics, cotraining with demonstration data generated both in simulation and on real hardware has emerged as a powerful recipe to overcome the sim2real gap. This work seeks to elucidate basic principles of this sim-and-real cotraining to help inform simulation design, sim-and-real dataset creation, and policy training. Focusing narrowly on the canonical task of planar pushing from camera inputs enabled us to be thorough in our study. These experiments confirm that cotraining with simulated data \emph{can} dramatically improve performance in real, especially when real data is limited. Performance gains scale with simulated data, but eventually plateau; real-world data increases this performance ceiling. The results also suggest that reducing the domain gap in physics may be more important than visual fidelity for non-prehensile manipulation tasks. Perhaps surprisingly, having some visual domain gap actually helps the cotrained policy -- binary probes reveal that high-performing policies learn to distinguish simulated domains from real. We conclude by investigating this nuance and mechanisms that facilitate positive transfer between sim-and-real. In total, our experiments span over 40 real-world policies (evaluated on 800+ trials) and 200 simulated policies (evaluated on 40,000+ trials).",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22634v1,imitation learning robotics cotraining demonstration data generated simulation real hardware emerged powerful recipe overcome sim2real gap work seek elucidate basic principle simandreal cotraining help inform simulation design simandreal dataset creation policy training focusing narrowly canonical task planar pushing camera input enabled u thorough study experiment confirm cotraining simulated data emphcan dramatically improve performance real especially real data limited performance gain scale simulated data eventually plateau realworld data increase performance ceiling result also suggest reducing domain gap physic may important visual fidelity nonprehensile manipulation task perhaps surprisingly visual domain gap actually help cotrained policy binary probe reveal highperforming policy learn distinguish simulated domain real conclude investigating nuance mechanism facilitate positive transfer simandreal total experiment span 40 realworld policy evaluated 800 trial 200 simulated policy evaluated 40000 trial
2503.22633v1,The moment polytope of matrix multiplication is not maximal,"['Maxim van den Berg', 'Matthias Christandl', 'Vladimir Lysikov', 'Harold Nieuwboer', 'Michael Walter', 'Jeroen Zuiddam']","Moment polytopes of tensors, the study of which is deeply rooted in invariant theory, representation theory and symplectic geometry, have found relevance in numerous places, from quantum information (entanglement polytopes) and algebraic complexity theory (GCT program and the complexity of matrix multiplication) to optimization (scaling algorithms). Towards an open problem in algebraic complexity theory, we prove separations between the moment polytopes of matrix multiplication tensors and unit tensors. As a consequence, we find that matrix multiplication moment polytopes are not maximal, i.e. are strictly contained in the corresponding Kronecker polytope. As another consequence, we obtain a no-go result for a natural operational characterization of moment polytope inclusion in terms of asymptotic restriction. We generalize the separation and non-maximality to moment polytopes of iterated matrix multiplication tensors. Our result implies that tensor networks where multipartite entanglement structures beyond two-party entanglement are allowed can go beyond projected entangled-pair states (PEPS) in terms of expressivity.   Our proof characterizes membership of uniform points in moment polytopes of tensors, and establishes a connection to polynomial multiplication tensors via the minrank of matrix subspaces. As a result of independent interest, we extend these techniques to obtain a new proof of the optimal border subrank bound for matrix multiplication.",2025-03-28,"['cs.CC', 'math.AG', 'math.RT', 'math.SG', 'quant-ph', '15A69, 14L24']",http://arxiv.org/pdf/2503.22633v1,moment polytopes tensor study deeply rooted invariant theory representation theory symplectic geometry found relevance numerous place quantum information entanglement polytopes algebraic complexity theory gct program complexity matrix multiplication optimization scaling algorithm towards open problem algebraic complexity theory prove separation moment polytopes matrix multiplication tensor unit tensor consequence find matrix multiplication moment polytopes maximal ie strictly contained corresponding kronecker polytope another consequence obtain nogo result natural operational characterization moment polytope inclusion term asymptotic restriction generalize separation nonmaximality moment polytopes iterated matrix multiplication tensor result implies tensor network multipartite entanglement structure beyond twoparty entanglement allowed go beyond projected entangledpair state pep term expressivity proof characterizes membership uniform point moment polytopes tensor establishes connection polynomial multiplication tensor via minrank matrix subspace result independent interest extend technique obtain new proof optimal border subrank bound matrix multiplication
2503.22631v1,Accelerating a restarted Krylov method for matrix functions with randomization,"['Nicolas L. Guidotti', 'Per-Gunnar Martinsson', 'Juan A. Acebrón', 'José Monteiro']","Many scientific applications require the evaluation of the action of the matrix function over a vector and the most common methods for this task are those based on the Krylov subspace. Since the orthogonalization cost and memory requirement can quickly become overwhelming as the basis grows, the Krylov method is often restarted after a few iterations. This paper proposes a new acceleration technique for restarted Krylov methods based on randomization. The numerical experiments show that the randomized method greatly outperforms the classical approach with the same level of accuracy. In fact, randomization can actually improve the convergence rate of restarted methods in some cases. The paper also compares the performance and stability of the randomized methods proposed so far for solving very large finite element problems, complementing the numerical analyses from previous studies.",2025-03-28,"['math.NA', 'cs.NA', '68W20, 65F60, 65F50, 65M20']",http://arxiv.org/pdf/2503.22631v1,many scientific application require evaluation action matrix function vector common method task based krylov subspace since orthogonalization cost memory requirement quickly become overwhelming basis grows krylov method often restarted iteration paper proposes new acceleration technique restarted krylov method based randomization numerical experiment show randomized method greatly outperforms classical approach level accuracy fact randomization actually improve convergence rate restarted method case paper also compare performance stability randomized method proposed far solving large finite element problem complementing numerical analysis previous study
2503.22629v1,Sentiment Classification of Thai Central Bank Press Releases Using Supervised Learning,['Stefano Grassi'],"Central bank communication plays a critical role in shaping economic expectations and monetary policy effectiveness. This study applies supervised machine learning techniques to classify the sentiment of press releases from the Bank of Thailand, addressing gaps in research that primarily focus on lexicon-based approaches. My findings show that supervised learning can be an effective method, even with smaller datasets, and serves as a starting point for further automation. However, achieving higher accuracy and better generalization requires a substantial amount of labeled data, which is time-consuming and demands expertise. Using models such as Na\""ive Bayes, Random Forest and SVM, this study demonstrates the applicability of machine learning for central bank sentiment analysis, with English-language communications from the Thai Central Bank as a case study.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22629v1,central bank communication play critical role shaping economic expectation monetary policy effectiveness study applies supervised machine learning technique classify sentiment press release bank thailand addressing gap research primarily focus lexiconbased approach finding show supervised learning effective method even smaller datasets serf starting point automation however achieving higher accuracy better generalization requires substantial amount labeled data timeconsuming demand expertise using model naive bayes random forest svm study demonstrates applicability machine learning central bank sentiment analysis englishlanguage communication thai central bank case study
2503.22625v1,Challenges and Paths Towards AI for Software Engineering,"['Alex Gu', 'Naman Jain', 'Wen-Ding Li', 'Manish Shetty', 'Yijia Shao', 'Ziyang Li', 'Diyi Yang', 'Kevin Ellis', 'Koushik Sen', 'Armando Solar-Lezama']","AI for software engineering has made remarkable progress recently, becoming a notable success within generative AI. Despite this, there are still many challenges that need to be addressed before automated software engineering reaches its full potential. It should be possible to reach high levels of automation where humans can focus on the critical decisions of what to build and how to balance difficult tradeoffs while most routine development effort is automated away. Reaching this level of automation will require substantial research and engineering efforts across academia and industry. In this paper, we aim to discuss progress towards this in a threefold manner. First, we provide a structured taxonomy of concrete tasks in AI for software engineering, emphasizing the many other tasks in software engineering beyond code generation and completion. Second, we outline several key bottlenecks that limit current approaches. Finally, we provide an opinionated list of promising research directions toward making progress on these bottlenecks, hoping to inspire future research in this rapidly maturing field.",2025-03-28,"['cs.SE', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22625v1,ai software engineering made remarkable progress recently becoming notable success within generative ai despite still many challenge need addressed automated software engineering reach full potential possible reach high level automation human focus critical decision build balance difficult tradeoff routine development effort automated away reaching level automation require substantial research engineering effort across academia industry paper aim discus progress towards threefold manner first provide structured taxonomy concrete task ai software engineering emphasizing many task software engineering beyond code generation completion second outline several key bottleneck limit current approach finally provide opinionated list promising research direction toward making progress bottleneck hoping inspire future research rapidly maturing field
2503.22622v1,Zero4D: Training-Free 4D Video Generation From Single Video Using Off-the-Shelf Video Diffusion Model,"['Jangho Park', 'Taesung Kwon', 'Jong Chul Ye']","Recently, multi-view or 4D video generation has emerged as a significant research topic. Nonetheless, recent approaches to 4D generation still struggle with fundamental limitations, as they primarily rely on harnessing multiple video diffusion models with additional training or compute-intensive training of a full 4D diffusion model with limited real-world 4D data and large computational costs. To address these challenges, here we propose the first training-free 4D video generation method that leverages the off-the-shelf video diffusion models to generate multi-view videos from a single input video. Our approach consists of two key steps: (1) By designating the edge frames in the spatio-temporal sampling grid as key frames, we first synthesize them using a video diffusion model, leveraging a depth-based warping technique for guidance. This approach ensures structural consistency across the generated frames, preserving spatial and temporal coherence. (2) We then interpolate the remaining frames using a video diffusion model, constructing a fully populated and temporally coherent sampling grid while preserving spatial and temporal consistency. Through this approach, we extend a single video into a multi-view video along novel camera trajectories while maintaining spatio-temporal consistency. Our method is training-free and fully utilizes an off-the-shelf video diffusion model, offering a practical and effective solution for multi-view video generation.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22622v1,recently multiview 4d video generation emerged significant research topic nonetheless recent approach 4d generation still struggle fundamental limitation primarily rely harnessing multiple video diffusion model additional training computeintensive training full 4d diffusion model limited realworld 4d data large computational cost address challenge propose first trainingfree 4d video generation method leverage offtheshelf video diffusion model generate multiview video single input video approach consists two key step 1 designating edge frame spatiotemporal sampling grid key frame first synthesize using video diffusion model leveraging depthbased warping technique guidance approach ensures structural consistency across generated frame preserving spatial temporal coherence 2 interpolate remaining frame using video diffusion model constructing fully populated temporally coherent sampling grid preserving spatial temporal consistency approach extend single video multiview video along novel camera trajectory maintaining spatiotemporal consistency method trainingfree fully utilizes offtheshelf video diffusion model offering practical effective solution multiview video generation
2503.22621v1,Improved error estimates for low-regularity integrators using space-time bounds,['Maximilian Ruff'],"We prove optimal convergence rates for certain low-regularity integrators applied to the one-dimensional periodic nonlinear Schr\""odinger and wave equations under the assumption of $H^1$ solutions. For the Schr\""odinger equation we analyze the exponential-type scheme proposed by Ostermann and Schratz in 2018, whereas in the wave case we treat the corrected Lie splitting proposed by Li, Schratz, and Zivcovich in 2023. We show that the integrators converge with their full order of one and two, respectively. In this situation only fractional convergence rates were previously known. The crucial ingredients in the proofs are known space-time bounds for the solutions to the corresponding linear problems. More precisely, in the Schr\""odinger case we use the $L^4$ Strichartz inequality, and for the wave equation a null form estimate. To our knowledge, this is the first time that a null form estimate is exploited in numerical analysis. We apply the estimates for continuous time, thus avoiding potential losses resulting from discrete-time estimates.",2025-03-28,"['math.NA', 'cs.NA', 'math.AP', '65M15 (Primary) 35L71, 35Q55, 65M12 (Secondary)']",http://arxiv.org/pdf/2503.22621v1,prove optimal convergence rate certain lowregularity integrator applied onedimensional periodic nonlinear schrodinger wave equation assumption h1 solution schrodinger equation analyze exponentialtype scheme proposed ostermann schratz 2018 whereas wave case treat corrected lie splitting proposed li schratz zivcovich 2023 show integrator converge full order one two respectively situation fractional convergence rate previously known crucial ingredient proof known spacetime bound solution corresponding linear problem precisely schrodinger case use l4 strichartz inequality wave equation null form estimate knowledge first time null form estimate exploited numerical analysis apply estimate continuous time thus avoiding potential loss resulting discretetime estimate
2503.22617v1,Using Machine Learning for Lunar Mineralogy-I: Hyperspectral Imaging of Volcanic Samples,"['Fatemeh Fazel Hesar', 'Mojtaba Raouf', 'Peyman Soltani', 'Bernard Foing', 'Michiel J. A. de Dood', 'Fons J. Verbeek', 'Esther Cheng', 'Chenming Zhou']","This study examines the mineral composition of volcanic samples similar to lunar materials, focusing on olivine and pyroxene. Using hyperspectral imaging from 400 to 1000 nm, we created data cubes to analyze the reflectance characteristics of samples from samples from Vulcano, a volcanically active island in the Aeolian Archipelago, north of Sicily, Italy, categorizing them into nine regions of interest and analyzing spectral data for each. We applied various unsupervised clustering algorithms, including K-Means, Hierarchical Clustering, GMM, and Spectral Clustering, to classify the spectral profiles. Principal Component Analysis revealed distinct spectral signatures associated with specific minerals, facilitating precise identification. Clustering performance varied by region, with K-Means achieving the highest silhouette-score of 0.47, whereas GMM performed poorly with a score of only 0.25. Non-negative Matrix Factorization aided in identifying similarities among clusters across different methods and reference spectra for olivine and pyroxene. Hierarchical clustering emerged as the most reliable technique, achieving a 94\% similarity with the olivine spectrum in one sample, whereas GMM exhibited notable variability. Overall, the analysis indicated that both Hierarchical and K-Means methods yielded lower errors in total measurements, with K-Means demonstrating superior performance in estimated dispersion and clustering. Additionally, GMM showed a higher root mean square error compared to the other models. The RMSE analysis confirmed K-Means as the most consistent algorithm across all samples, suggesting a predominance of olivine in the Vulcano region relative to pyroxene. This predominance is likely linked to historical formation conditions similar to volcanic processes on the Moon, where olivine-rich compositions are common in ancient lava flows and impact melt rocks.",2025-03-28,"['astro-ph.EP', 'cs.LG']",http://arxiv.org/pdf/2503.22617v1,study examines mineral composition volcanic sample similar lunar material focusing olivine pyroxene using hyperspectral imaging 400 1000 nm created data cube analyze reflectance characteristic sample sample vulcano volcanically active island aeolian archipelago north sicily italy categorizing nine region interest analyzing spectral data applied various unsupervised clustering algorithm including kmeans hierarchical clustering gmm spectral clustering classify spectral profile principal component analysis revealed distinct spectral signature associated specific mineral facilitating precise identification clustering performance varied region kmeans achieving highest silhouettescore 047 whereas gmm performed poorly score 025 nonnegative matrix factorization aided identifying similarity among cluster across different method reference spectrum olivine pyroxene hierarchical clustering emerged reliable technique achieving 94 similarity olivine spectrum one sample whereas gmm exhibited notable variability overall analysis indicated hierarchical kmeans method yielded lower error total measurement kmeans demonstrating superior performance estimated dispersion clustering additionally gmm showed higher root mean square error compared model rmse analysis confirmed kmeans consistent algorithm across sample suggesting predominance olivine vulcano region relative pyroxene predominance likely linked historical formation condition similar volcanic process moon olivinerich composition common ancient lava flow impact melt rock
2503.22613v1,Randomized $\tilde{O}(m\sqrt{n})$ Bellman-Ford from Fineman and the Boilermakers,['Satish Rao'],"A classical algorithm by Bellman and Ford from the 1950's computes shortest paths in weighted graphs on $n$ vertices and $m$ edges with possibly negative weights in $O(mn)$ time. Indeed, this algorithm is taught regularly in undergraduate Algorithms courses.   In 2023, after nearly 70 years, Fineman \cite{fineman2024single} developed an $\tilde{O}(m n^{8/9})$ expected time algorithm for this problem. Huang, Jin and Quanrud improved on Fineman's startling breakthrough by providing an $\tilde{O}(m n^{4/5} )$ time algorithm.   This paper builds on ideas from those results to produce an $\tilde{O}(m\sqrt{n})$ expected time algorithm. The simple observation that distances can be updated with respect to the reduced costs for a price function in linear time is key to the improvement. This almost immediately improves the previous work. To produce the final bound, this paper provides recursive versions of Fineman's structures.",2025-03-28,"['cs.DS', 'cs.CC']",http://arxiv.org/pdf/2503.22613v1,classical algorithm bellman ford 1950s computes shortest path weighted graph n vertex edge possibly negative weight omn time indeed algorithm taught regularly undergraduate algorithm course 2023 nearly 70 year fineman citefineman2024single developed tildeom n89 expected time algorithm problem huang jin quanrud improved finemans startling breakthrough providing tildeom n45 time algorithm paper build idea result produce tildeomsqrtn expected time algorithm simple observation distance updated respect reduced cost price function linear time key improvement almost immediately improves previous work produce final bound paper provides recursive version finemans structure
2503.22612v1,Advancing DevSecOps in SMEs: Challenges and Best Practices for Secure CI/CD Pipelines,"['Jayaprakashreddy Cheenepalli', 'John D. Hastings', 'Khandaker Mamun Ahmed', 'Chad Fenner']","This study evaluates the adoption of DevSecOps among small and medium-sized enterprises (SMEs), identifying key challenges, best practices, and future trends. Through a mixed methods approach backed by the Technology Acceptance Model (TAM) and Diffusion of Innovations (DOI) theory, we analyzed survey data from 405 SME professionals, revealing that while 68% have implemented DevSecOps, adoption is hindered by technical complexity (41%), resource constraints (35%), and cultural resistance (38%). Despite strong leadership prioritization of security (73%), automation gaps persist, with only 12% of organizations conducting security scans per commit.   Our findings highlight a growing integration of security tools, particularly API security (63%) and software composition analysis (62%), although container security adoption remains low (34%). Looking ahead, SMEs anticipate artificial intelligence and machine learning to significantly influence DevSecOps, underscoring the need for proactive adoption of AI-driven security enhancements. Based on our findings, this research proposes strategic best practices to enhance CI/CD pipeline security including automation, leadership-driven security culture, and cross-team collaboration.",2025-03-28,"['cs.CR', 'cs.CY', 'cs.SE', 'D.2.2; K.6.5; D.2.9']",http://arxiv.org/pdf/2503.22612v1,study evaluates adoption devsecops among small mediumsized enterprise smes identifying key challenge best practice future trend mixed method approach backed technology acceptance model tam diffusion innovation doi theory analyzed survey data 405 sme professional revealing 68 implemented devsecops adoption hindered technical complexity 41 resource constraint 35 cultural resistance 38 despite strong leadership prioritization security 73 automation gap persist 12 organization conducting security scan per commit finding highlight growing integration security tool particularly api security 63 software composition analysis 62 although container security adoption remains low 34 looking ahead smes anticipate artificial intelligence machine learning significantly influence devsecops underscoring need proactive adoption aidriven security enhancement based finding research proposes strategic best practice enhance cicd pipeline security including automation leadershipdriven security culture crossteam collaboration
2503.22610v1,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"['Antonia Karamolegkou', 'Malvina Nikandrou', 'Georgios Pantazopoulos', 'Danae Sanchez Villegas', 'Phillip Rust', 'Ruchira Dhar', 'Daniel Hershcovich', 'Anders Søgaard']","This paper explores the effectiveness of Multimodal Large Language models (MLLMs) as assistive technologies for visually impaired individuals. We conduct a user survey to identify adoption patterns and key challenges users face with such technologies. Despite a high adoption rate of these models, our findings highlight concerns related to contextual understanding, cultural sensitivity, and complex scene understanding, particularly for individuals who may rely solely on them for visual interpretation. Informed by these results, we collate five user-centred tasks with image and video inputs, including a novel task on Optical Braille Recognition. Our systematic evaluation of twelve MLLMs reveals that further advancements are necessary to overcome limitations related to cultural context, multilingual support, Braille reading comprehension, assistive object recognition, and hallucinations. This work provides critical insights into the future direction of multimodal AI for accessibility, underscoring the need for more inclusive, robust, and trustworthy visual assistance technologies.",2025-03-28,"['cs.HC', 'cs.AI', 'cs.CL', 'cs.CY', 'cs.LG']",http://arxiv.org/pdf/2503.22610v1,paper explores effectiveness multimodal large language model mllms assistive technology visually impaired individual conduct user survey identify adoption pattern key challenge user face technology despite high adoption rate model finding highlight concern related contextual understanding cultural sensitivity complex scene understanding particularly individual may rely solely visual interpretation informed result collate five usercentred task image video input including novel task optical braille recognition systematic evaluation twelve mllms reveals advancement necessary overcome limitation related cultural context multilingual support braille reading comprehension assistive object recognition hallucination work provides critical insight future direction multimodal ai accessibility underscoring need inclusive robust trustworthy visual assistance technology
2503.22605v1,Audio-Plane: Audio Factorization Plane Gaussian Splatting for Real-Time Talking Head Synthesis,"['Shuai Shen', 'Wanhua Li', 'Yunpeng Zhang', 'Weipeng Hu', 'Yap-Peng Tan']","Talking head synthesis has become a key research area in computer graphics and multimedia, yet most existing methods often struggle to balance generation quality with computational efficiency. In this paper, we present a novel approach that leverages an Audio Factorization Plane (Audio-Plane) based Gaussian Splatting for high-quality and real-time talking head generation. For modeling a dynamic talking head, 4D volume representation is needed. However, directly storing a dense 4D grid is impractical due to the high cost and lack of scalability for longer durations. We overcome this challenge with the proposed Audio-Plane, where the 4D volume representation is decomposed into audio-independent space planes and audio-dependent planes. This provides a compact and interpretable feature representation for talking head, facilitating more precise audio-aware spatial encoding and enhanced audio-driven lip dynamic modeling. To further improve speech dynamics, we develop a dynamic splatting method that helps the network more effectively focus on modeling the dynamics of the mouth region. Extensive experiments demonstrate that by integrating these innovations with the powerful Gaussian Splatting, our method is capable of synthesizing highly realistic talking videos in real time while ensuring precise audio-lip synchronization. Synthesized results are available in https://sstzal.github.io/Audio-Plane/.",2025-03-28,"['cs.GR', 'cs.CV', 'cs.SD', 'eess.AS']",http://arxiv.org/pdf/2503.22605v1,talking head synthesis become key research area computer graphic multimedia yet existing method often struggle balance generation quality computational efficiency paper present novel approach leverage audio factorization plane audioplane based gaussian splatting highquality realtime talking head generation modeling dynamic talking head 4d volume representation needed however directly storing dense 4d grid impractical due high cost lack scalability longer duration overcome challenge proposed audioplane 4d volume representation decomposed audioindependent space plane audiodependent plane provides compact interpretable feature representation talking head facilitating precise audioaware spatial encoding enhanced audiodriven lip dynamic modeling improve speech dynamic develop dynamic splatting method help network effectively focus modeling dynamic mouth region extensive experiment demonstrate integrating innovation powerful gaussian splatting method capable synthesizing highly realistic talking video real time ensuring precise audiolip synchronization synthesized result available httpssstzalgithubioaudioplane
2503.22601v1,Neural Identification of Feedback-Stabilized Nonlinear Systems,"['Mahrokh G. Boroujeni', 'Laura Meroi', 'Leonardo Massai', 'Clara L. Galimberti', 'Giancarlo Ferrari-Trecate']","Neural networks have demonstrated remarkable success in modeling nonlinear dynamical systems. However, identifying these systems from closed-loop experimental data remains a challenge due to the correlations induced by the feedback loop. Traditional nonlinear closed-loop system identification methods struggle with reliance on precise noise models, robustness to data variations, or computational feasibility. Additionally, it is essential to ensure that the identified model is stabilized by the same controller used during data collection, ensuring alignment with the true system's closed-loop behavior. The dual Youla parameterization provides a promising solution for linear systems, offering statistical guarantees and closed-loop stability. However, extending this approach to nonlinear systems presents additional complexities. In this work, we propose a computationally tractable framework for identifying complex, potentially unstable systems while ensuring closed-loop stability using a complete parameterization of systems stabilized by a given controller. We establish asymptotic consistency in the linear case and validate our method through numerical comparisons, demonstrating superior accuracy over direct identification baselines and compatibility with the true system in stability properties.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22601v1,neural network demonstrated remarkable success modeling nonlinear dynamical system however identifying system closedloop experimental data remains challenge due correlation induced feedback loop traditional nonlinear closedloop system identification method struggle reliance precise noise model robustness data variation computational feasibility additionally essential ensure identified model stabilized controller used data collection ensuring alignment true system closedloop behavior dual youla parameterization provides promising solution linear system offering statistical guarantee closedloop stability however extending approach nonlinear system present additional complexity work propose computationally tractable framework identifying complex potentially unstable system ensuring closedloop stability using complete parameterization system stabilized given controller establish asymptotic consistency linear case validate method numerical comparison demonstrating superior accuracy direct identification baseline compatibility true system stability property
2503.22600v1,Generative Latent Neural PDE Solver using Flow Matching,"['Zijie Li', 'Anthony Zhou', 'Amir Barati Farimani']","Autoregressive next-step prediction models have become the de-facto standard for building data-driven neural solvers to forecast time-dependent partial differential equations (PDEs). Denoise training that is closely related to diffusion probabilistic model has been shown to enhance the temporal stability of neural solvers, while its stochastic inference mechanism enables ensemble predictions and uncertainty quantification. In principle, such training involves sampling a series of discretized diffusion timesteps during both training and inference, inevitably increasing computational overhead. In addition, most diffusion models apply isotropic Gaussian noise on structured, uniform grids, limiting their adaptability to irregular domains. We propose a latent diffusion model for PDE simulation that embeds the PDE state in a lower-dimensional latent space, which significantly reduces computational costs. Our framework uses an autoencoder to map different types of meshes onto a unified structured latent grid, capturing complex geometries. By analyzing common diffusion paths, we propose to use a coarsely sampled noise schedule from flow matching for both training and testing. Numerical experiments show that the proposed model outperforms several deterministic baselines in both accuracy and long-term stability, highlighting the potential of diffusion-based approaches for robust data-driven PDE learning.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22600v1,autoregressive nextstep prediction model become defacto standard building datadriven neural solver forecast timedependent partial differential equation pdes denoise training closely related diffusion probabilistic model shown enhance temporal stability neural solver stochastic inference mechanism enables ensemble prediction uncertainty quantification principle training involves sampling series discretized diffusion timesteps training inference inevitably increasing computational overhead addition diffusion model apply isotropic gaussian noise structured uniform grid limiting adaptability irregular domain propose latent diffusion model pde simulation embeds pde state lowerdimensional latent space significantly reduces computational cost framework us autoencoder map different type mesh onto unified structured latent grid capturing complex geometry analyzing common diffusion path propose use coarsely sampled noise schedule flow matching training testing numerical experiment show proposed model outperforms several deterministic baseline accuracy longterm stability highlighting potential diffusionbased approach robust datadriven pde learning
2503.22595v1,Reinforcement Learning for Machine Learning Model Deployment: Evaluating Multi-Armed Bandits in ML Ops Environments,"['S. Aaron McClendon', 'Vishaal Venkatesh', 'Juan Morinelli']","In modern ML Ops environments, model deployment is a critical process that traditionally relies on static heuristics such as validation error comparisons and A/B testing. However, these methods require human intervention to adapt to real-world deployment challenges, such as model drift or unexpected performance degradation. We investigate whether reinforcement learning, specifically multi-armed bandit (MAB) algorithms, can dynamically manage model deployment decisions more effectively. Our approach enables more adaptive production environments by continuously evaluating deployed models and rolling back underperforming ones in real-time. We test six model selection strategies across two real-world datasets and find that RL based approaches match or exceed traditional methods in performance. Our findings suggest that reinforcement learning (RL)-based model management can improve automation, reduce reliance on manual interventions, and mitigate risks associated with post-deployment model failures.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22595v1,modern ml ops environment model deployment critical process traditionally relies static heuristic validation error comparison ab testing however method require human intervention adapt realworld deployment challenge model drift unexpected performance degradation investigate whether reinforcement learning specifically multiarmed bandit mab algorithm dynamically manage model deployment decision effectively approach enables adaptive production environment continuously evaluating deployed model rolling back underperforming one realtime test six model selection strategy across two realworld datasets find rl based approach match exceed traditional method performance finding suggest reinforcement learning rlbased model management improve automation reduce reliance manual intervention mitigate risk associated postdeployment model failure
2503.22594v1,On the Alignment of Post-Publication Reviews & Bibliometric and Altmetric Impact -- A Case Study on Expert Statements from the Science Media Center Germany,"['Dirk Tunger', 'Philipp Schaer']","In the context of academic publishing and peer review, this study investigates the relationship between post-publication expert evaluations, their agreement levels, and the subsequent scientific and public recognition of the reviewed research. Using expert statements from the Science Media Center Germany as a dataset, we analyze Research in Context reviews to examine the alignment between qualitative post-publication assessments and bibliometric as well as altmetric indicators. We employ a Large Language Model to translate unstructured expert reviews into a structured rating scheme. Furthermore, we correlate these evaluations with citation counts from the Web of Science and alternative impact metrics such as the Altmetric Attention Score, news mentions, and Mendeley readership statistics from the Altmetric Explorer. We investigate the alignment of positive or critical post-publication reviews and high or low citation or altmetric counts.",2025-03-28,['cs.DL'],http://arxiv.org/pdf/2503.22594v1,context academic publishing peer review study investigates relationship postpublication expert evaluation agreement level subsequent scientific public recognition reviewed research using expert statement science medium center germany dataset analyze research context review examine alignment qualitative postpublication assessment bibliometric well altmetric indicator employ large language model translate unstructured expert review structured rating scheme furthermore correlate evaluation citation count web science alternative impact metric altmetric attention score news mention mendeley readership statistic altmetric explorer investigate alignment positive critical postpublication review high low citation altmetric count
2503.22592v1,KEVS: Enhancing Segmentation of Visceral Adipose Tissue in Pre-Cystectomy CT with Gaussian Kernel Density Estimation,"['Thomas Boucher', 'Nicholas Tetlow', 'Annie Fung', 'Amy Dewar', 'Pietro Arina', 'Sven Kerneis', 'John Whittle', 'Evangelos B. Mazomenos']","Purpose: The distribution of visceral adipose tissue (VAT) in cystectomy patients is indicative of the incidence of post-operative complications. Existing VAT segmentation methods for computed tomography (CT) employing intensity thresholding have limitations relating to inter-observer variability. Moreover, the difficulty in creating ground-truth masks limits the development of deep learning (DL) models for this task. This paper introduces a novel method for VAT prediction in pre-cystectomy CT, which is fully automated and does not require ground-truth VAT masks for training, overcoming aforementioned limitations. Methods: We introduce the Kernel density Enhanced VAT Segmentator ( KEVS), combining a DL semantic segmentation model, for multi-body feature prediction, with Gaussian kernel density estimation analysis of predicted subcutaneous adipose tissue to achieve accurate scan-specific predictions of VAT in the abdominal cavity. Uniquely for a DL pipeline, KEVS does not require ground-truth VAT masks. Results: We verify the ability of KEVS to accurately segment abdominal organs in unseen CT data and compare KEVS VAT segmentation predictions to existing state-of-the-art (SOTA) approaches in a dataset of 20 pre-cystectomy CT scans, collected from University College London Hospital (UCLH-Cyst), with expert ground-truth annotations. KEVS presents a 4.80% and 6.02% improvement in Dice Coefficient over the second best DL and thresholding-based VAT segmentation techniques respectively when evaluated on UCLH-Cyst. Conclusion: This research introduces KEVS; an automated, SOTA method for the prediction of VAT in pre-cystectomy CT which eliminates inter-observer variability and is trained entirely on open-source CT datasets which do not contain ground-truth VAT masks.",2025-03-28,"['eess.IV', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22592v1,purpose distribution visceral adipose tissue vat cystectomy patient indicative incidence postoperative complication existing vat segmentation method computed tomography ct employing intensity thresholding limitation relating interobserver variability moreover difficulty creating groundtruth mask limit development deep learning dl model task paper introduces novel method vat prediction precystectomy ct fully automated require groundtruth vat mask training overcoming aforementioned limitation method introduce kernel density enhanced vat segmentator kevs combining dl semantic segmentation model multibody feature prediction gaussian kernel density estimation analysis predicted subcutaneous adipose tissue achieve accurate scanspecific prediction vat abdominal cavity uniquely dl pipeline kevs require groundtruth vat mask result verify ability kevs accurately segment abdominal organ unseen ct data compare kevs vat segmentation prediction existing stateoftheart sota approach dataset 20 precystectomy ct scan collected university college london hospital uclhcyst expert groundtruth annotation kevs present 480 602 improvement dice coefficient second best dl thresholdingbased vat segmentation technique respectively evaluated uclhcyst conclusion research introduces kevs automated sota method prediction vat precystectomy ct eliminates interobserver variability trained entirely opensource ct datasets contain groundtruth vat mask
2503.22589v1,"Using AI to Summarize US Presidential Campaign TV Advertisement Videos, 1952-2012","['Adam Breuer', 'Bryce J. Dietrich', 'Michael H. Crespin', 'Matthew Butler', 'J. A. Pyrse', 'Kosuke Imai']","This paper introduces the largest and most comprehensive dataset of US presidential campaign television advertisements, available in digital format. The dataset also includes machine-searchable transcripts and high-quality summaries designed to facilitate a variety of academic research. To date, there has been great interest in collecting and analyzing US presidential campaign advertisements, but the need for manual procurement and annotation led many to rely on smaller subsets. We design a large-scale parallelized, AI-based analysis pipeline that automates the laborious process of preparing, transcribing, and summarizing videos. We then apply this methodology to the 9,707 presidential ads from the Julian P. Kanter Political Commercial Archive. We conduct extensive human evaluations to show that these transcripts and summaries match the quality of manually generated alternatives. We illustrate the value of this data by including an application that tracks the genesis and evolution of current focal issue areas over seven decades of presidential elections. Our analysis pipeline and codebase also show how to use LLM-based tools to obtain high-quality summaries for other video datasets.",2025-03-28,"['cs.MM', 'cs.AI', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22589v1,paper introduces largest comprehensive dataset u presidential campaign television advertisement available digital format dataset also includes machinesearchable transcript highquality summary designed facilitate variety academic research date great interest collecting analyzing u presidential campaign advertisement need manual procurement annotation led many rely smaller subset design largescale parallelized aibased analysis pipeline automates laborious process preparing transcribing summarizing video apply methodology 9707 presidential ad julian p kanter political commercial archive conduct extensive human evaluation show transcript summary match quality manually generated alternative illustrate value data including application track genesis evolution current focal issue area seven decade presidential election analysis pipeline codebase also show use llmbased tool obtain highquality summary video datasets
2503.22587v1,LLM-enabled Instance Model Generation,"['Fengjunjie Pan', 'Nenad Petrovic', 'Vahid Zolfaghari', 'Long Wen', 'Alois Knoll']","In the domain of model-based engineering, models are essential components that enable system design and analysis. Traditionally, the creation of these models has been a manual process requiring not only deep modeling expertise but also substantial domain knowledge of target systems. With the rapid advancement of generative artificial intelligence, large language models (LLMs) show potential for automating model generation. This work explores the generation of instance models using LLMs, focusing specifically on producing XMI-based instance models from Ecore metamodels and natural language specifications. We observe that current LLMs struggle to directly generate valid XMI models. To address this, we propose a two-step approach: first, using LLMs to produce a simplified structured output containing all necessary instance model information, namely a conceptual instance model, and then compiling this intermediate representation into a valid XMI file. The conceptual instance model is format-independent, allowing it to be transformed into various modeling formats via different compilers. The feasibility of the proposed method has been demonstrated using several LLMs, including GPT-4o, o1-preview, Llama 3.1 (8B and 70B). Results show that the proposed method significantly improves the usability of LLMs for instance model generation tasks. Notably, the smaller open-source model, Llama 3.1 70B, demonstrated performance comparable to proprietary GPT models within the proposed framework.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22587v1,domain modelbased engineering model essential component enable system design analysis traditionally creation model manual process requiring deep modeling expertise also substantial domain knowledge target system rapid advancement generative artificial intelligence large language model llm show potential automating model generation work explores generation instance model using llm focusing specifically producing xmibased instance model ecore metamodels natural language specification observe current llm struggle directly generate valid xmi model address propose twostep approach first using llm produce simplified structured output containing necessary instance model information namely conceptual instance model compiling intermediate representation valid xmi file conceptual instance model formatindependent allowing transformed various modeling format via different compiler feasibility proposed method demonstrated using several llm including gpt4o o1preview llama 31 8b 70b result show proposed method significantly improves usability llm instance model generation task notably smaller opensource model llama 31 70b demonstrated performance comparable proprietary gpt model within proposed framework
2503.22588v1,Next-Best-Trajectory Planning of Robot Manipulators for Effective Observation and Exploration,"['Heiko Renz', 'Maximilian Krämer', 'Frank Hoffmann', 'Torsten Bertram']","Visual observation of objects is essential for many robotic applications, such as object reconstruction and manipulation, navigation, and scene understanding. Machine learning algorithms constitute the state-of-the-art in many fields but require vast data sets, which are costly and time-intensive to collect. Automated strategies for observation and exploration are crucial to enhance the efficiency of data gathering. Therefore, a novel strategy utilizing the Next-Best-Trajectory principle is developed for a robot manipulator operating in dynamic environments. Local trajectories are generated to maximize the information gained from observations along the path while avoiding collisions. We employ a voxel map for environment modeling and utilize raycasting from perspectives around a point of interest to estimate the information gain. A global ergodic trajectory planner provides an optional reference trajectory to the local planner, improving exploration and helping to avoid local minima. To enhance computational efficiency, raycasting for estimating the information gain in the environment is executed in parallel on the graphics processing unit. Benchmark results confirm the efficiency of the parallelization, while real-world experiments demonstrate the strategy's effectiveness.",2025-03-28,"['cs.RO', 'cs.CV', 'cs.HC']",http://arxiv.org/pdf/2503.22588v1,visual observation object essential many robotic application object reconstruction manipulation navigation scene understanding machine learning algorithm constitute stateoftheart many field require vast data set costly timeintensive collect automated strategy observation exploration crucial enhance efficiency data gathering therefore novel strategy utilizing nextbesttrajectory principle developed robot manipulator operating dynamic environment local trajectory generated maximize information gained observation along path avoiding collision employ voxel map environment modeling utilize raycasting perspective around point interest estimate information gain global ergodic trajectory planner provides optional reference trajectory local planner improving exploration helping avoid local minimum enhance computational efficiency raycasting estimating information gain environment executed parallel graphic processing unit benchmark result confirm efficiency parallelization realworld experiment demonstrate strategy effectiveness
2503.22585v1,Historical Ink: Exploring Large Language Models for Irony Detection in 19th-Century Spanish,"['Kevin Cohen', 'Laura Manrique-Gómez', 'Rubén Manrique']","This study explores the use of large language models (LLMs) to enhance datasets and improve irony detection in 19th-century Latin American newspapers. Two strategies were employed to evaluate the efficacy of BERT and GPT-4o models in capturing the subtle nuances nature of irony, through both multi-class and binary classification tasks. First, we implemented dataset enhancements focused on enriching emotional and contextual cues; however, these showed limited impact on historical language analysis. The second strategy, a semi-automated annotation process, effectively addressed class imbalance and augmented the dataset with high-quality annotations. Despite the challenges posed by the complexity of irony, this work contributes to the advancement of sentiment analysis through two key contributions: introducing a new historical Spanish dataset tagged for sentiment analysis and irony detection, and proposing a semi-automated annotation methodology where human expertise is crucial for refining LLMs results, enriched by incorporating historical and cultural contexts as core features.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.DL', 'I.2.7']",http://arxiv.org/pdf/2503.22585v1,study explores use large language model llm enhance datasets improve irony detection 19thcentury latin american newspaper two strategy employed evaluate efficacy bert gpt4o model capturing subtle nuance nature irony multiclass binary classification task first implemented dataset enhancement focused enriching emotional contextual cue however showed limited impact historical language analysis second strategy semiautomated annotation process effectively addressed class imbalance augmented dataset highquality annotation despite challenge posed complexity irony work contributes advancement sentiment analysis two key contribution introducing new historical spanish dataset tagged sentiment analysis irony detection proposing semiautomated annotation methodology human expertise crucial refining llm result enriched incorporating historical cultural context core feature
2503.22584v1,Do Researchers Benefit Career-wise from Involvement in International Policy Guideline Development?,"['Yuta Tomokiyo', 'Keita Nishimoto', 'Kimitaka Asatani', 'Ichiro Sakata']","Researchers are no longer limited to producing knowledge; in today's complex world, they also address societal challenges by engaging in policymaking. Although involvement in policymaking has expanded, direct empirical evidence of its career benefits remains underexplored. Prior survey-based studies suggest potential advantages-such as broader professional networks and enhanced opportunities-yet raise concerns about insufficient institutional support. Here, we examine the 2021 WHO global air quality guideline-a science-based regulatory guideline-as a case study. To evaluate the impact of guideline development on research outcomes, we match guideline researchers with a control group of peers sharing similar research topics and prior performance. Our analysis reveals that guideline researchers attain higher future citation counts in both academic and policy domains. New collaborations formed during development yield publications with higher citation impact and the disruptive index. Moreover, about half the guideline's references are derived from guideline researchers' papers, highlighting their central role in shaping the evidence base. These results provide empirical support for the career benefits of policy engagement. Our findings indicate that engaging in international guideline development offers tangible career incentives for researchers, and that institutions can enhance research impact and promote innovative scientific progress by actively supporting their researchers' participation in such initiatives.",2025-03-28,['cs.SI'],http://arxiv.org/pdf/2503.22584v1,researcher longer limited producing knowledge today complex world also address societal challenge engaging policymaking although involvement policymaking expanded direct empirical evidence career benefit remains underexplored prior surveybased study suggest potential advantagessuch broader professional network enhanced opportunitiesyet raise concern insufficient institutional support examine 2021 global air quality guidelinea sciencebased regulatory guidelineas case study evaluate impact guideline development research outcome match guideline researcher control group peer sharing similar research topic prior performance analysis reveals guideline researcher attain higher future citation count academic policy domain new collaboration formed development yield publication higher citation impact disruptive index moreover half guideline reference derived guideline researcher paper highlighting central role shaping evidence base result provide empirical support career benefit policy engagement finding indicate engaging international guideline development offer tangible career incentive researcher institution enhance research impact promote innovative scientific progress actively supporting researcher participation initiative
2503.22582v1,"Beyond Vanilla Fine-Tuning: Leveraging Multistage, Multilingual, and Domain-Specific Methods for Low-Resource Machine Translation","['Sarubi Thillainathan', 'Songchen Yuan', 'En-Shiun Annie Lee', 'Sanath Jayasena', 'Surangika Ranathunga']","Fine-tuning multilingual sequence-to-sequence large language models (msLLMs) has shown promise in developing neural machine translation (NMT) systems for low-resource languages (LRLs). However, conventional single-stage fine-tuning methods struggle in extremely low-resource NMT settings, where training data is very limited. This paper contributes to artificial intelligence by proposing two approaches for adapting msLLMs in these challenging scenarios: (1) continual pre-training (CPT), where the msLLM is further trained with domain-specific monolingual data to compensate for the under-representation of LRLs, and (2) intermediate task transfer learning (ITTL), a method that fine-tunes the msLLM with both in-domain and out-of-domain parallel data to enhance its translation capabilities across various domains and tasks. As an application in engineering, these methods are implemented in NMT systems for Sinhala, Tamil, and English (six language pairs) in domain-specific, extremely low-resource settings (datasets containing fewer than 100,000 samples). Our experiments reveal that these approaches enhance translation performance by an average of +1.47 bilingual evaluation understudy (BLEU) score compared to the standard single-stage fine-tuning baseline across all translation directions. Additionally, a multi-model ensemble further improves performance by an additional BLEU score.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22582v1,finetuning multilingual sequencetosequence large language model msllms shown promise developing neural machine translation nmt system lowresource language lrls however conventional singlestage finetuning method struggle extremely lowresource nmt setting training data limited paper contributes artificial intelligence proposing two approach adapting msllms challenging scenario 1 continual pretraining cpt msllm trained domainspecific monolingual data compensate underrepresentation lrls 2 intermediate task transfer learning ittl method finetunes msllm indomain outofdomain parallel data enhance translation capability across various domain task application engineering method implemented nmt system sinhala tamil english six language pair domainspecific extremely lowresource setting datasets containing fewer 100000 sample experiment reveal approach enhance translation performance average 147 bilingual evaluation understudy bleu score compared standard singlestage finetuning baseline across translation direction additionally multimodel ensemble improves performance additional bleu score
2503.22577v1,Breaking Language Barriers in Visual Language Models via Multilingual Textual Regularization,"['Iñigo Pikabea', 'Iñaki Lacunza', 'Oriol Pareras', 'Carlos Escolano', 'Aitor Gonzalez-Agirre', 'Javier Hernando', 'Marta Villegas']","Rapid advancements in Visual Language Models (VLMs) have transformed multimodal understanding but are often constrained by generating English responses regardless of the input language. This phenomenon has been termed as Image-induced Fidelity Loss (IFL) and stems from limited multimodal multilingual training data. To address this, we propose a continuous multilingual integration strategy that injects text-only multilingual data during visual instruction tuning, preserving the language model's original multilingual capabilities. Extensive evaluations demonstrate that our approach significantly improves linguistic fidelity across languages without degradation in visual performance. We also explore model merging, which improves language fidelity but comes at the cost of visual performance. In contrast, our core method achieves robust multilingual alignment without trade-offs, offering a scalable and effective path to mitigating IFL for global VLM adoption.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22577v1,rapid advancement visual language model vlms transformed multimodal understanding often constrained generating english response regardless input language phenomenon termed imageinduced fidelity loss ifl stem limited multimodal multilingual training data address propose continuous multilingual integration strategy injects textonly multilingual data visual instruction tuning preserving language model original multilingual capability extensive evaluation demonstrate approach significantly improves linguistic fidelity across language without degradation visual performance also explore model merging improves language fidelity come cost visual performance contrast core method achieves robust multilingual alignment without tradeoff offering scalable effective path mitigating ifl global vlm adoption
2503.22576v1,Drop the Golden Apples: Identifying Third-Party Reuse by DB-Less Software Composition Analysis,"['Lyuye Zhang', 'Chengwei Liu', 'Jiahui Wu', 'Shiyang Zhang', 'Chengyue Liu', 'Zhengzi Xu', 'Sen Chen', 'Yang Liu']","The prevalent use of third-party libraries (TPLs) in modern software development introduces significant security and compliance risks, necessitating the implementation of Software Composition Analysis (SCA) to manage these threats. However, the accuracy of SCA tools heavily relies on the quality of the integrated feature database to cross-reference with user projects. While under the circumstance of the exponentially growing of open-source ecosystems and the integration of large models into software development, it becomes even more challenging to maintain a comprehensive feature database for potential TPLs. To this end, after referring to the evolution of LLM applications in terms of external data interactions, we propose the first framework of DB-Less SCA, to get rid of the traditional heavy database and embrace the flexibility of LLMs to mimic the manual analysis of security analysts to retrieve identical evidence and confirm the identity of TPLs by supportive information from the open Internet. Our experiments on two typical scenarios, native library identification for Android and copy-based TPL reuse for C/C++, especially on artifacts that are not that underappreciated, have demonstrated the favorable future for implementing database-less strategies in SCA.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22576v1,prevalent use thirdparty library tpls modern software development introduces significant security compliance risk necessitating implementation software composition analysis sca manage threat however accuracy sca tool heavily relies quality integrated feature database crossreference user project circumstance exponentially growing opensource ecosystem integration large model software development becomes even challenging maintain comprehensive feature database potential tpls end referring evolution llm application term external data interaction propose first framework dbless sca get rid traditional heavy database embrace flexibility llm mimic manual analysis security analyst retrieve identical evidence confirm identity tpls supportive information open internet experiment two typical scenario native library identification android copybased tpl reuse cc especially artifact underappreciated demonstrated favorable future implementing databaseless strategy sca
2503.22575v1,On the Mistaken Assumption of Interchangeable Deep Reinforcement Learning Implementations,"['Rajdeep Singh Hundal', 'Yan Xiao', 'Xiaochun Cao', 'Jin Song Dong', 'Manuel Rigger']","Deep Reinforcement Learning (DRL) is a paradigm of artificial intelligence where an agent uses a neural network to learn which actions to take in a given environment. DRL has recently gained traction from being able to solve complex environments like driving simulators, 3D robotic control, and multiplayer-online-battle-arena video games. Numerous implementations of the state-of-the-art algorithms responsible for training these agents, like the Deep Q-Network (DQN) and Proximal Policy Optimization (PPO) algorithms, currently exist. However, studies make the mistake of assuming implementations of the same algorithm to be consistent and thus, interchangeable. In this paper, through a differential testing lens, we present the results of studying the extent of implementation inconsistencies, their effect on the implementations' performance, as well as their impact on the conclusions of prior studies under the assumption of interchangeable implementations. The outcomes of our differential tests showed significant discrepancies between the tested algorithm implementations, indicating that they are not interchangeable. In particular, out of the five PPO implementations tested on 56 games, three implementations achieved superhuman performance for 50% of their total trials while the other two implementations only achieved superhuman performance for less than 15% of their total trials. As part of a meticulous manual analysis of the implementations' source code, we analyzed implementation discrepancies and determined that code-level inconsistencies primarily caused these discrepancies. Lastly, we replicated a study and showed that this assumption of implementation interchangeability was sufficient to flip experiment outcomes. Therefore, this calls for a shift in how implementations are being used.",2025-03-28,"['cs.SE', 'cs.AI', 'D.2.5; I.2.6']",http://arxiv.org/pdf/2503.22575v1,deep reinforcement learning drl paradigm artificial intelligence agent us neural network learn action take given environment drl recently gained traction able solve complex environment like driving simulator 3d robotic control multiplayeronlinebattlearena video game numerous implementation stateoftheart algorithm responsible training agent like deep qnetwork dqn proximal policy optimization ppo algorithm currently exist however study make mistake assuming implementation algorithm consistent thus interchangeable paper differential testing lens present result studying extent implementation inconsistency effect implementation performance well impact conclusion prior study assumption interchangeable implementation outcome differential test showed significant discrepancy tested algorithm implementation indicating interchangeable particular five ppo implementation tested 56 game three implementation achieved superhuman performance 50 total trial two implementation achieved superhuman performance le 15 total trial part meticulous manual analysis implementation source code analyzed implementation discrepancy determined codelevel inconsistency primarily caused discrepancy lastly replicated study showed assumption implementation interchangeability sufficient flip experiment outcome therefore call shift implementation used
2503.22574v1,Task Hierarchical Control via Null-Space Projection and Path Integral Approach,"['Apurva Patil', 'Riku Funada', 'Takashi Tanaka', 'Luis Sentis']","This paper addresses the problem of hierarchical task control, where a robotic system must perform multiple subtasks with varying levels of priority. A commonly used approach for hierarchical control is the null-space projection technique, which ensures that higher-priority tasks are executed without interference from lower-priority ones. While effective, the state-of-the-art implementations of this method rely on low-level controllers, such as PID controllers, which can be prone to suboptimal solutions in complex tasks. This paper presents a novel framework for hierarchical task control, integrating the null-space projection technique with the path integral control method. Our approach leverages Monte Carlo simulations for real-time computation of optimal control inputs, allowing for the seamless integration of simpler PID-like controllers with a more sophisticated optimal control technique. Through simulation studies, we demonstrate the effectiveness of this combined approach, showing how it overcomes the limitations of traditional",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22574v1,paper address problem hierarchical task control robotic system must perform multiple subtasks varying level priority commonly used approach hierarchical control nullspace projection technique ensures higherpriority task executed without interference lowerpriority one effective stateoftheart implementation method rely lowlevel controller pid controller prone suboptimal solution complex task paper present novel framework hierarchical task control integrating nullspace projection technique path integral control method approach leverage monte carlo simulation realtime computation optimal control input allowing seamless integration simpler pidlike controller sophisticated optimal control technique simulation study demonstrate effectiveness combined approach showing overcomes limitation traditional
2503.22573v1,A Framework for Cryptographic Verifiability of End-to-End AI Pipelines,"['Kar Balan', 'Robert Learney', 'Tim Wood']","The increasing integration of Artificial Intelligence across multiple industry sectors necessitates robust mechanisms for ensuring transparency, trust, and auditability of its development and deployment. This topic is particularly important in light of recent calls in various jurisdictions to introduce regulation and legislation on AI safety. In this paper, we propose a framework for complete verifiable AI pipelines, identifying key components and analyzing existing cryptographic approaches that contribute to verifiability across different stages of the AI lifecycle, from data sourcing to training, inference, and unlearning. This framework could be used to combat misinformation by providing cryptographic proofs alongside AI-generated assets to allow downstream verification of their provenance and correctness. Our findings underscore the importance of ongoing research to develop cryptographic tools that are not only efficient for isolated AI processes, but that are efficiently `linkable' across different processes within the AI pipeline, to support the development of end-to-end verifiable AI technologies.",2025-03-28,"['cs.CR', 'cs.AI']",http://arxiv.org/pdf/2503.22573v1,increasing integration artificial intelligence across multiple industry sector necessitates robust mechanism ensuring transparency trust auditability development deployment topic particularly important light recent call various jurisdiction introduce regulation legislation ai safety paper propose framework complete verifiable ai pipeline identifying key component analyzing existing cryptographic approach contribute verifiability across different stage ai lifecycle data sourcing training inference unlearning framework could used combat misinformation providing cryptographic proof alongside aigenerated asset allow downstream verification provenance correctness finding underscore importance ongoing research develop cryptographic tool efficient isolated ai process efficiently linkable across different process within ai pipeline support development endtoend verifiable ai technology
2503.22569v1,Comparing Methods for Bias Mitigation in Graph Neural Networks,"['Barbara Hoffmann', 'Ruben Mayer']","This paper examines the critical role of Graph Neural Networks (GNNs) in data preparation for generative artificial intelligence (GenAI) systems, with a particular focus on addressing and mitigating biases. We present a comparative analysis of three distinct methods for bias mitigation: data sparsification, feature modification, and synthetic data augmentation. Through experimental analysis using the german credit dataset, we evaluate these approaches using multiple fairness metrics, including statistical parity, equality of opportunity, and false positive rates. Our research demonstrates that while all methods improve fairness metrics compared to the original dataset, stratified sampling and synthetic data augmentation using GraphSAGE prove particularly effective in balancing demographic representation while maintaining model performance. The results provide practical insights for developing more equitable AI systems while maintaining model performance.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22569v1,paper examines critical role graph neural network gnns data preparation generative artificial intelligence genai system particular focus addressing mitigating bias present comparative analysis three distinct method bias mitigation data sparsification feature modification synthetic data augmentation experimental analysis using german credit dataset evaluate approach using multiple fairness metric including statistical parity equality opportunity false positive rate research demonstrates method improve fairness metric compared original dataset stratified sampling synthetic data augmentation using graphsage prove particularly effective balancing demographic representation maintaining model performance result provide practical insight developing equitable ai system maintaining model performance
2503.22567v1,Benchmarking Ultra-Low-Power $μ$NPUs,"['Josh Millar', 'Yushan Huang', 'Sarab Sethi', 'Hamed Haddadi', 'Anil Madhavapeddy']","Efficient on-device neural network (NN) inference has various advantages over cloud-based processing, including predictable latency, enhanced privacy, greater reliability, and reduced operating costs for vendors. This has sparked the recent rapid development of microcontroller-scale NN accelerators, often referred to as neural processing units ($\mu$NPUs), designed specifically for ultra-low-power applications.   In this paper we present the first comparative evaluation of a number of commercially-available $\mu$NPUs, as well as the first independent benchmarks for several of these platforms. We develop and open-source a model compilation framework to enable consistent benchmarking of quantized models across diverse $\mu$NPU hardware. Our benchmark targets end-to-end performance and includes model inference latency, power consumption, and memory overhead, alongside other factors. The resulting analysis uncovers both expected performance trends as well as surprising disparities between hardware specifications and actual performance, including $\mu$NPUs exhibiting unexpected scaling behaviors with increasing model complexity. Our framework provides a foundation for further evaluation of $\mu$NPU platforms alongside valuable insights for both hardware designers and software developers in this rapidly evolving space.",2025-03-28,"['cs.LG', 'cs.AR']",http://arxiv.org/pdf/2503.22567v1,efficient ondevice neural network nn inference various advantage cloudbased processing including predictable latency enhanced privacy greater reliability reduced operating cost vendor sparked recent rapid development microcontrollerscale nn accelerator often referred neural processing unit munpus designed specifically ultralowpower application paper present first comparative evaluation number commerciallyavailable munpus well first independent benchmark several platform develop opensource model compilation framework enable consistent benchmarking quantized model across diverse munpu hardware benchmark target endtoend performance includes model inference latency power consumption memory overhead alongside factor resulting analysis uncovers expected performance trend well surprising disparity hardware specification actual performance including munpus exhibiting unexpected scaling behavior increasing model complexity framework provides foundation evaluation munpu platform alongside valuable insight hardware designer software developer rapidly evolving space
2503.22563v1,RELD: Regularization by Latent Diffusion Models for Image Restoration,"['Pasquale Cascarano', 'Lorenzo Stacchio', 'Andrea Sebastiani', 'Alessandro Benfenati', 'Ulugbek S. Kamilov', 'Gustavo Marfia']","In recent years, Diffusion Models have become the new state-of-the-art in deep generative modeling, ending the long-time dominance of Generative Adversarial Networks. Inspired by the Regularization by Denoising principle, we introduce an approach that integrates a Latent Diffusion Model, trained for the denoising task, into a variational framework using Half-Quadratic Splitting, exploiting its regularization properties. This approach, under appropriate conditions that can be easily met in various imaging applications, allows for reduced computational cost while achieving high-quality results. The proposed strategy, called Regularization by Latent Denoising (RELD), is then tested on a dataset of natural images, for image denoising, deblurring, and super-resolution tasks. The numerical experiments show that RELD is competitive with other state-of-the-art methods, particularly achieving remarkable results when evaluated using perceptual quality metrics.",2025-03-28,"['eess.IV', 'cs.CV']",http://arxiv.org/pdf/2503.22563v1,recent year diffusion model become new stateoftheart deep generative modeling ending longtime dominance generative adversarial network inspired regularization denoising principle introduce approach integrates latent diffusion model trained denoising task variational framework using halfquadratic splitting exploiting regularization property approach appropriate condition easily met various imaging application allows reduced computational cost achieving highquality result proposed strategy called regularization latent denoising reld tested dataset natural image image denoising deblurring superresolution task numerical experiment show reld competitive stateoftheart method particularly achieving remarkable result evaluated using perceptual quality metric
2503.22562v1,Niyama : Breaking the Silos of LLM Inference Serving,"['Kanishk Goel', 'Jayashree Mohan', 'Nipun Kwatra', 'Ravi Shreyas Anupindi', 'Ramachandran Ramjee']","The widespread adoption of Large Language Models (LLMs) has enabled diverse applications with very different latency requirements. Existing LLM serving frameworks rely on siloed infrastructure with coarse-grained workload segregation -- interactive and batch -- leading to inefficient resource utilization and limited support for fine-grained Quality-of-Service (QoS) differentiation. This results in operational inefficiencies, over-provisioning and poor load management during traffic surges.   We present Niyama, a novel QoS-driven inference serving system that enables efficient co-scheduling of diverse workloads on shared infrastructure. Niyama introduces fine-grained QoS classification allowing applications to specify precise latency requirements, and dynamically adapts scheduling decisions based on real-time system state. Leveraging the predictable execution characteristics of LLM inference, Niyama implements a dynamic chunking mechanism to improve overall throughput while maintaining strict QoS guarantees. Additionally, Niyama employs a hybrid prioritization policy that balances fairness and efficiency, and employs selective request relegation that enables graceful service degradation during overload conditions. Our evaluation demonstrates that Niyama increases serving capacity by 32% compared to current siloed deployments, while maintaining QoS guarantees. Notably, under extreme load, our system reduces SLO violations by an order of magnitude compared to current strategies.",2025-03-28,"['cs.LG', 'cs.AI', 'cs.DC']",http://arxiv.org/pdf/2503.22562v1,widespread adoption large language model llm enabled diverse application different latency requirement existing llm serving framework rely siloed infrastructure coarsegrained workload segregation interactive batch leading inefficient resource utilization limited support finegrained qualityofservice qos differentiation result operational inefficiency overprovisioning poor load management traffic surge present niyama novel qosdriven inference serving system enables efficient coscheduling diverse workload shared infrastructure niyama introduces finegrained qos classification allowing application specify precise latency requirement dynamically adapts scheduling decision based realtime system state leveraging predictable execution characteristic llm inference niyama implement dynamic chunking mechanism improve overall throughput maintaining strict qos guarantee additionally niyama employ hybrid prioritization policy balance fairness efficiency employ selective request relegation enables graceful service degradation overload condition evaluation demonstrates niyama increase serving capacity 32 compared current siloed deployment maintaining qos guarantee notably extreme load system reduces slo violation order magnitude compared current strategy
2503.22560v1,Image Decomposition with G-norm Weighted by Total Symmetric Variation,"['Roy Y. He', 'Martin Huska', 'Hao Liu']","In this paper, we propose a novel variational model for decomposing images into their respective cartoon and texture parts. Our model characterizes certain non-local features of any Bounded Variation (BV) image by its Total Symmetric Variation (TSV). We demonstrate that TSV is effective in identifying regional boundaries. Based on this property, we introduce a weighted Meyer's $G$-norm to identify texture interiors without including contour edges. For BV images with bounded TSV, we show that the proposed model admits a solution. Additionally, we design a fast algorithm based on operator-splitting to tackle the associated non-convex optimization problem. The performance of our method is validated by a series of numerical experiments.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22560v1,paper propose novel variational model decomposing image respective cartoon texture part model characterizes certain nonlocal feature bounded variation bv image total symmetric variation tsv demonstrate tsv effective identifying regional boundary based property introduce weighted meyers gnorm identify texture interior without including contour edge bv image bounded tsv show proposed model admits solution additionally design fast algorithm based operatorsplitting tackle associated nonconvex optimization problem performance method validated series numerical experiment
2503.22558v1,Algorithmic analysis of systems with affine input and polynomial state,['Lorenzo Clemente'],"The goal of this paper is to provide exact and terminating algorithms for the formal analysis of deterministic continuous-time control systems with affine input and polynomial state dynamics (in short, polynomial systems). We consider the following semantic properties: zeroness and equivalence, input independence, linearity, and analyticity. Our approach is based on Chen-Fliess series, which provide a unique representation of the dynamics of such systems via their formal generating series.   Our starting point is Fliess' seminal work showing how the semantic properties above are mirrored by corresponding combinatorial properties on generating series. Next, we observe that the generating series of polynomial systems coincide with the class of shuffle-finite series, a nonlinear generalisation of Sch\""utzenberger's rational series which has recently been studied in the context of automata theory and enumerative combinatorics. We exploit and extend recent results in the algorithmic analysis of shuffle-finite series (such as zeroness, equivalence, and commutativity) to show that the semantic properties above can be decided exactly and in finite time for polynomial systems. Some of our analyses rely on a novel technical contribution, namely that shuffle-finite series are closed under support restrictions with commutative regular languages, a result of independent interest.",2025-03-28,"['cs.FL', 'cs.LO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22558v1,goal paper provide exact terminating algorithm formal analysis deterministic continuoustime control system affine input polynomial state dynamic short polynomial system consider following semantic property zeroness equivalence input independence linearity analyticity approach based chenfliess series provide unique representation dynamic system via formal generating series starting point flies seminal work showing semantic property mirrored corresponding combinatorial property generating series next observe generating series polynomial system coincide class shufflefinite series nonlinear generalisation schutzenbergers rational series recently studied context automaton theory enumerative combinatorics exploit extend recent result algorithmic analysis shufflefinite series zeroness equivalence commutativity show semantic property decided exactly finite time polynomial system analysis rely novel technical contribution namely shufflefinite series closed support restriction commutative regular language result independent interest
2503.22557v1,MO-CTranS: A unified multi-organ segmentation model learning from multiple heterogeneously labelled datasets,"['Zhendi Gong', 'Susan Francis', 'Eleanor Cox', 'Stamatios N. Sotiropoulos', 'Dorothee P. Auer', 'Guoping Qiu', 'Andrew P. French', 'Xin Chen']","Multi-organ segmentation holds paramount significance in many clinical tasks. In practice, compared to large fully annotated datasets, multiple small datasets are often more accessible and organs are not labelled consistently. Normally, an individual model is trained for each of these datasets, which is not an effective way of using data for model learning. It remains challenging to train a single model that can robustly learn from several partially labelled datasets due to label conflict and data imbalance problems. We propose MO-CTranS: a single model that can overcome such problems. MO-CTranS contains a CNN-based encoder and a Transformer-based decoder, which are connected in a multi-resolution manner. Task-specific tokens are introduced in the decoder to help differentiate label discrepancies. Our method was evaluated and compared to several baseline models and state-of-the-art (SOTA) solutions on abdominal MRI datasets that were acquired in different views (i.e. axial and coronal) and annotated for different organs (i.e. liver, kidney, spleen). Our method achieved better performance (most were statistically significant) than the compared methods. Github link: https://github.com/naisops/MO-CTranS.",2025-03-28,"['cs.CV', 'I.2; I.4.6']",http://arxiv.org/pdf/2503.22557v1,multiorgan segmentation hold paramount significance many clinical task practice compared large fully annotated datasets multiple small datasets often accessible organ labelled consistently normally individual model trained datasets effective way using data model learning remains challenging train single model robustly learn several partially labelled datasets due label conflict data imbalance problem propose moctrans single model overcome problem moctrans contains cnnbased encoder transformerbased decoder connected multiresolution manner taskspecific token introduced decoder help differentiate label discrepancy method evaluated compared several baseline model stateoftheart sota solution abdominal mri datasets acquired different view ie axial coronal annotated different organ ie liver kidney spleen method achieved better performance statistically significant compared method github link httpsgithubcomnaisopsmoctrans
2503.22547v1,Bridging the Dimensional Chasm: Uncover Layer-wise Dimensional Reduction in Transformers through Token Correlation,"['Zhuo-Yang Song', 'Zeyu Li', 'Qing-Hong Cao', 'Ming-xing Luo', 'Hua Xing Zhu']","The geometric evolution of token representations in large language models (LLMs) presents a fundamental paradox: while human language inherently organizes semantic information in low-dimensional spaces ($\sim 10^1$ dimensions), modern LLMs employ high-dimensional embeddings ($\sim 10^3$ dimensions) processed through Transformer architectures. To resolve this paradox, this work bridges this conceptual gap by developing a geometric framework that tracks token dynamics across Transformers layers. Through layer-wise analysis of intrinsic dimensions across multiple architectures, we reveal an expansion-contraction pattern where tokens diffuse to a ""working space"" and then progressively project onto lower-dimensional submanifolds. Our finding implies a negative correlation between the working space dimension and parameter-sensitive performance of the LLMs, and indicates that effective models tend to compress tokens into approximately 10-dimensional submanifolds, closely resembling human semantic spaces. This work not only advances LLM interpretability by reframing Transformers layers as projectors that mediate between high-dimensional computation and low-dimensional semantics, but also provides practical tools for model diagnostics that do not rely on task-specific evaluations.",2025-03-28,"['cs.CL', 'cs.LG']",http://arxiv.org/pdf/2503.22547v1,geometric evolution token representation large language model llm present fundamental paradox human language inherently organizes semantic information lowdimensional space sim 101 dimension modern llm employ highdimensional embeddings sim 103 dimension processed transformer architecture resolve paradox work bridge conceptual gap developing geometric framework track token dynamic across transformer layer layerwise analysis intrinsic dimension across multiple architecture reveal expansioncontraction pattern token diffuse working space progressively project onto lowerdimensional submanifolds finding implies negative correlation working space dimension parametersensitive performance llm indicates effective model tend compress token approximately 10dimensional submanifolds closely resembling human semantic space work advance llm interpretability reframing transformer layer projector mediate highdimensional computation lowdimensional semantics also provides practical tool model diagnostics rely taskspecific evaluation
2503.22546v1,Pseudovarieties of semigroups,['Jorge Almeida'],"The most developed aspect of the theory of finite semigroups is their classification in pseudovarieties. The main motivation for investigating such entities comes from their connection with the classification of regular languages via Eilenberg's correspondence. This connection prompted the study of various natural operators on pseudovarieties and led to several important questions, both algebraic and algorithmic. The most important of these questions is decidability: given a finite semigroup is there an algorithm that tests whether it belongs to the pseudovariety? Since the most relevant operators on pseudovarieties do not preserve decidability, one often seeks to establish stronger properties. A key role is played by relatively free profinite semigroups, which is the counterpart of free algebras in universal algebra. The purpose of this paper is to give a brief survey of the state of the art, highlighting some of the main developments and problems.",2025-03-28,"['math.GR', 'cs.FL', '20M07, 20M35']",http://arxiv.org/pdf/2503.22546v1,developed aspect theory finite semigroups classification pseudovarieties main motivation investigating entity come connection classification regular language via eilenbergs correspondence connection prompted study various natural operator pseudovarieties led several important question algebraic algorithmic important question decidability given finite semigroup algorithm test whether belongs pseudovariety since relevant operator pseudovarieties preserve decidability one often seek establish stronger property key role played relatively free profinite semigroups counterpart free algebra universal algebra purpose paper give brief survey state art highlighting main development problem
2503.22541v1,SafeCast: Risk-Responsive Motion Forecasting for Autonomous Vehicles,"['Haicheng Liao', 'Hanlin Kong', 'Bin Rao', 'Bonan Wang', 'Chengyue Wang', 'Guyang Yu', 'Yuming Huang', 'Ruru Tang', 'Chengzhong Xu', 'Zhenning Li']","Accurate motion forecasting is essential for the safety and reliability of autonomous driving (AD) systems. While existing methods have made significant progress, they often overlook explicit safety constraints and struggle to capture the complex interactions among traffic agents, environmental factors, and motion dynamics. To address these challenges, we present SafeCast, a risk-responsive motion forecasting model that integrates safety-aware decision-making with uncertainty-aware adaptability. SafeCast is the first to incorporate the Responsibility-Sensitive Safety (RSS) framework into motion forecasting, encoding interpretable safety rules--such as safe distances and collision avoidance--based on traffic norms and physical principles. To further enhance robustness, we introduce the Graph Uncertainty Feature (GUF), a graph-based module that injects learnable noise into Graph Attention Networks, capturing real-world uncertainties and enhancing generalization across diverse scenarios. We evaluate SafeCast on four real-world benchmark datasets--Next Generation Simulation (NGSIM), Highway Drone (HighD), ApolloScape, and the Macao Connected Autonomous Driving (MoCAD)--covering highway, urban, and mixed-autonomy traffic environments. Our model achieves state-of-the-art (SOTA) accuracy while maintaining a lightweight architecture and low inference latency, underscoring its potential for real-time deployment in safety-critical AD systems.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22541v1,accurate motion forecasting essential safety reliability autonomous driving ad system existing method made significant progress often overlook explicit safety constraint struggle capture complex interaction among traffic agent environmental factor motion dynamic address challenge present safecast riskresponsive motion forecasting model integrates safetyaware decisionmaking uncertaintyaware adaptability safecast first incorporate responsibilitysensitive safety r framework motion forecasting encoding interpretable safety rulessuch safe distance collision avoidancebased traffic norm physical principle enhance robustness introduce graph uncertainty feature guf graphbased module injects learnable noise graph attention network capturing realworld uncertainty enhancing generalization across diverse scenario evaluate safecast four realworld benchmark datasetsnext generation simulation ngsim highway drone highd apolloscape macao connected autonomous driving mocadcovering highway urban mixedautonomy traffic environment model achieves stateoftheart sota accuracy maintaining lightweight architecture low inference latency underscoring potential realtime deployment safetycritical ad system
2503.22539v1,Efficient Verified Machine Unlearning For Distillation,"['Yijun Quan', 'Zushu Li', 'Giovanni Montana']","Growing data privacy demands, driven by regulations like GDPR and CCPA, require machine unlearning methods capable of swiftly removing the influence of specific training points. Although verified approaches like SISA, using data slicing and checkpointing, achieve efficient unlearning for single models by reverting to intermediate states, these methods struggle in teacher-student knowledge distillation settings. Unlearning in the teacher typically forces costly, complete student retraining due to pervasive information propagation during distillation. Our primary contribution is PURGE (Partitioned Unlearning with Retraining Guarantee for Ensembles), a novel framework integrating verified unlearning with distillation. We introduce constituent mapping and an incremental multi-teacher strategy that partitions the distillation process, confines each teacher constituent's impact to distinct student data subsets, and crucially maintains data isolation. The PURGE framework substantially reduces retraining overhead, requiring only partial student updates when teacher-side unlearning occurs. We provide both theoretical analysis, quantifying significant speed-ups in the unlearning process, and empirical validation on multiple datasets, demonstrating that PURGE achieves these efficiency gains while maintaining student accuracy comparable to standard baselines.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22539v1,growing data privacy demand driven regulation like gdpr ccpa require machine unlearning method capable swiftly removing influence specific training point although verified approach like sisa using data slicing checkpointing achieve efficient unlearning single model reverting intermediate state method struggle teacherstudent knowledge distillation setting unlearning teacher typically force costly complete student retraining due pervasive information propagation distillation primary contribution purge partitioned unlearning retraining guarantee ensemble novel framework integrating verified unlearning distillation introduce constituent mapping incremental multiteacher strategy partition distillation process confines teacher constituent impact distinct student data subset crucially maintains data isolation purge framework substantially reduces retraining overhead requiring partial student update teacherside unlearning occurs provide theoretical analysis quantifying significant speedup unlearning process empirical validation multiple datasets demonstrating purge achieves efficiency gain maintaining student accuracy comparable standard baseline
2503.22537v1,LIM: Large Interpolator Model for Dynamic Reconstruction,"['Remy Sabathier', 'Niloy J. Mitra', 'David Novotny']","Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks. Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods. Inspired by the recent Large Reconstruction Model (LRM), we present the Large Interpolation Model (LIM), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time. Given implicit 3D representations at times $t_0$ and $t_1$, LIM produces a deformed shape at any continuous time $t\in[t_0,t_1]$, delivering high-quality interpolated frames in seconds. Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines. We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos. We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM) and direct triplane linear interpolation, and demonstrate clear advantages. In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.",2025-03-28,"['cs.CV', 'cs.AI']",http://arxiv.org/pdf/2503.22537v1,reconstructing dynamic asset video data central many computer vision graphic task existing 4d reconstruction approach limited categoryspecific model slow optimizationbased method inspired recent large reconstruction model lrm present large interpolation model lim transformerbased feedforward solution guided novel causal consistency loss interpolating implicit 3d representation across time given implicit 3d representation time t0 t1 lim produce deformed shape continuous time tint0t1 delivering highquality interpolated frame second furthermore lim allows explicit mesh tracking across time producing consistently uvtextured mesh sequence ready integration existing production pipeline also use lim conjunction diffusionbased multiview generator produce dynamic 4d reconstruction monocular video evaluate lim various dynamic datasets benchmarking imagespace interpolation method eg film direct triplane linear interpolation demonstrate clear advantage summary lim first feedforward model capable highspeed tracked 4d asset reconstruction across diverse category
2503.22531v1,Deterministic Medical Image Translation via High-fidelity Brownian Bridges,"['Qisheng He', 'Nicholas Summerfield', 'Peiyong Wang', 'Carri Glide-Hurst', 'Ming Dong']","Recent studies have shown that diffusion models produce superior synthetic images when compared to Generative Adversarial Networks (GANs). However, their outputs are often non-deterministic and lack high fidelity to the ground truth due to the inherent randomness. In this paper, we propose a novel High-fidelity Brownian bridge model (HiFi-BBrg) for deterministic medical image translations. Our model comprises two distinct yet mutually beneficial mappings: a generation mapping and a reconstruction mapping. The Brownian bridge training process is guided by the fidelity loss and adversarial training in the reconstruction mapping. This ensures that translated images can be accurately reversed to their original forms, thereby achieving consistent translations with high fidelity to the ground truth. Our extensive experiments on multiple datasets show HiFi-BBrg outperforms state-of-the-art methods in multi-modal image translation and multi-image super-resolution.",2025-03-28,"['eess.IV', 'cs.CV', 'cs.LG']",http://arxiv.org/pdf/2503.22531v1,recent study shown diffusion model produce superior synthetic image compared generative adversarial network gans however output often nondeterministic lack high fidelity ground truth due inherent randomness paper propose novel highfidelity brownian bridge model hifibbrg deterministic medical image translation model comprises two distinct yet mutually beneficial mapping generation mapping reconstruction mapping brownian bridge training process guided fidelity loss adversarial training reconstruction mapping ensures translated image accurately reversed original form thereby achieving consistent translation high fidelity ground truth extensive experiment multiple datasets show hifibbrg outperforms stateoftheart method multimodal image translation multiimage superresolution
2503.22528v1,MixFunn: A Neural Network for Differential Equations with Improved Generalization and Interpretability,"['Tiago de Souza Farias', 'Gubio Gomes de Lima', 'Jonas Maziero', 'Celso Jorge Villas-Boas']","We introduce MixFunn, a novel neural network architecture designed to solve differential equations with enhanced precision, interpretability, and generalization capability. The architecture comprises two key components: the mixed-function neuron, which integrates multiple parameterized nonlinear functions to improve representational flexibility, and the second-order neuron, which combines a linear transformation of its inputs with a quadratic term to capture cross-combinations of input variables. These features significantly enhance the expressive power of the network, enabling it to achieve comparable or superior results with drastically fewer parameters and a reduction of up to four orders of magnitude compared to conventional approaches. We applied MixFunn in a physics-informed setting to solve differential equations in classical mechanics, quantum mechanics, and fluid dynamics, demonstrating its effectiveness in achieving higher accuracy and improved generalization to regions outside the training domain relative to standard machine learning models. Furthermore, the architecture facilitates the extraction of interpretable analytical expressions, offering valuable insights into the underlying solutions.",2025-03-28,"['cs.LG', 'physics.app-ph', 'physics.comp-ph']",http://arxiv.org/pdf/2503.22528v1,introduce mixfunn novel neural network architecture designed solve differential equation enhanced precision interpretability generalization capability architecture comprises two key component mixedfunction neuron integrates multiple parameterized nonlinear function improve representational flexibility secondorder neuron combine linear transformation input quadratic term capture crosscombinations input variable feature significantly enhance expressive power network enabling achieve comparable superior result drastically fewer parameter reduction four order magnitude compared conventional approach applied mixfunn physicsinformed setting solve differential equation classical mechanic quantum mechanic fluid dynamic demonstrating effectiveness achieving higher accuracy improved generalization region outside training domain relative standard machine learning model furthermore architecture facilitates extraction interpretable analytical expression offering valuable insight underlying solution
2503.22526v1,AnnoPage Dataset: Dataset of Non-Textual Elements in Documents with Fine-Grained Categorization,"['Martin Kišš', 'Michal Hradiš', 'Martina Dvořáková', 'Václav Jiroušek', 'Filip Kersch']","We introduce the AnnoPage Dataset, a novel collection of 7550 pages from historical documents, primarily in Czech and German, spanning from 1485 to the present, focusing on the late 19th and early 20th centuries. The dataset is designed to support research in document layout analysis and object detection. Each page is annotated with axis-aligned bounding boxes (AABB) representing elements of 25 categories of non-textual elements, such as images, maps, decorative elements, or charts, following the Czech Methodology of image document processing. The annotations were created by expert librarians to ensure accuracy and consistency. The dataset also incorporates pages from multiple, mainly historical, document datasets to enhance variability and maintain continuity. The dataset is divided into development and test subsets, with the test set carefully selected to maintain the category distribution. We provide baseline results using YOLO and DETR object detectors, offering a reference point for future research. The AnnoPage Dataset is publicly available on Zenodo (https://doi.org/10.5281/zenodo.12788419), along with ground-truth annotations in YOLO format.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22526v1,introduce annopage dataset novel collection 7550 page historical document primarily czech german spanning 1485 present focusing late 19th early 20th century dataset designed support research document layout analysis object detection page annotated axisaligned bounding box aabb representing element 25 category nontextual element image map decorative element chart following czech methodology image document processing annotation created expert librarian ensure accuracy consistency dataset also incorporates page multiple mainly historical document datasets enhance variability maintain continuity dataset divided development test subset test set carefully selected maintain category distribution provide baseline result using yolo detr object detector offering reference point future research annopage dataset publicly available zenodo httpsdoiorg105281zenodo12788419 along groundtruth annotation yolo format
2503.22524v1,Robust Offline Imitation Learning Through State-level Trajectory Stitching,"['Shuze Wang', 'Yunpeng Mei', 'Hongjie Cao', 'Yetian Yuan', 'Gang Wang', 'Jian Sun', 'Jie Chen']","Imitation learning (IL) has proven effective for enabling robots to acquire visuomotor skills through expert demonstrations. However, traditional IL methods are limited by their reliance on high-quality, often scarce, expert data, and suffer from covariate shift. To address these challenges, recent advances in offline IL have incorporated suboptimal, unlabeled datasets into the training. In this paper, we propose a novel approach to enhance policy learning from mixed-quality offline datasets by leveraging task-relevant trajectory fragments and rich environmental dynamics. Specifically, we introduce a state-based search framework that stitches state-action pairs from imperfect demonstrations, generating more diverse and informative training trajectories. Experimental results on standard IL benchmarks and real-world robotic tasks showcase that our proposed method significantly improves both generalization and performance.",2025-03-28,"['cs.RO', 'cs.AI']",http://arxiv.org/pdf/2503.22524v1,imitation learning il proven effective enabling robot acquire visuomotor skill expert demonstration however traditional il method limited reliance highquality often scarce expert data suffer covariate shift address challenge recent advance offline il incorporated suboptimal unlabeled datasets training paper propose novel approach enhance policy learning mixedquality offline datasets leveraging taskrelevant trajectory fragment rich environmental dynamic specifically introduce statebased search framework stitch stateaction pair imperfect demonstration generating diverse informative training trajectory experimental result standard il benchmark realworld robotic task showcase proposed method significantly improves generalization performance
2503.22522v1,A Centralized Planning and Distributed Execution Method for Shape Filling with Homogeneous Mobile Robots,"['Shuqing Liu', 'Rong Su', 'Karl H. Johansson']","Nature has inspired humans in different ways. The formation behavior of animals can perform tasks that exceed individual capability. For example, army ants could transverse gaps by forming bridges, and fishes could group up to protect themselves from predators. The pattern formation task is essential in a multiagent robotic system because it usually serves as the initial configuration of downstream tasks, such as collective manipulation and adaptation to various environments. The formation of complex shapes, especially hollow shapes, remains an open question. Traditional approaches either require global coordinates for each robot or are prone to failure when attempting to close the hole due to accumulated localization errors. Inspired by the ribbon idea introduced in the additive self-assembly algorithm by the Kilobot team, we develop a two-stage algorithm that does not require global coordinates information and effectively forms shapes with holes. In this paper, we investigate the partitioning of the shape using ribbons in a hexagonal lattice setting and propose the add-subtract algorithm based on the movement sequence induced by the ribbon structure. This advancement opens the door to tasks requiring complex pattern formations, such as the assembly of nanobots for medical applications involving intricate structures and the deployment of robots along the boundaries of areas of interest. We also provide simulation results on complex shapes, an analysis of the robustness as well as a proof of correctness of the proposed algorithm.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22522v1,nature inspired human different way formation behavior animal perform task exceed individual capability example army ant could transverse gap forming bridge fish could group protect predator pattern formation task essential multiagent robotic system usually serf initial configuration downstream task collective manipulation adaptation various environment formation complex shape especially hollow shape remains open question traditional approach either require global coordinate robot prone failure attempting close hole due accumulated localization error inspired ribbon idea introduced additive selfassembly algorithm kilobot team develop twostage algorithm require global coordinate information effectively form shape hole paper investigate partitioning shape using ribbon hexagonal lattice setting propose addsubtract algorithm based movement sequence induced ribbon structure advancement open door task requiring complex pattern formation assembly nanobots medical application involving intricate structure deployment robot along boundary area interest also provide simulation result complex shape analysis robustness well proof correctness proposed algorithm
2503.22521v1,Distributed Freeze Tag: a Sustainable Solution to Discover and Wake-up a Robot Swarm,"['Cyril Gavoille', 'Nicolas Hanusse', 'Gabriel Le Bouder', 'Taïssir Marcé']","The Freeze Tag Problem consists in waking up a swarm of robots starting with one initially awake robot. Whereas there is a wide literature of the centralized setting, where the location of the robots is known in advance, we focus in the distributed version where the location of the robots $\P$ are unknown, and where awake robots only detect other robots up to distance~$1$. Assuming that moving at distance $\delta$ takes a time $\delta$, we show that waking up of the whole swarm takes $O(\rho+\ell^2\log( \rho/\ell))$, where $\rho$ stands for the largest distance from the initial robot to any point of $\P$, and the $\ell$ is the connectivity threshold of $\P$. Moreover, the result is complemented by a matching lower bound in both parameters $\rho$ and $\ell$. We also provide other distributed algorithms, complemented with lower bounds, whenever each robot has a bounded amount of energy.",2025-03-28,['cs.DS'],http://arxiv.org/pdf/2503.22521v1,freeze tag problem consists waking swarm robot starting one initially awake robot whereas wide literature centralized setting location robot known advance focus distributed version location robot p unknown awake robot detect robot distance1 assuming moving distance delta take time delta show waking whole swarm take orhoell2log rhoell rho stand largest distance initial robot point p ell connectivity threshold p moreover result complemented matching lower bound parameter rho ell also provide distributed algorithm complemented lower bound whenever robot bounded amount energy
2503.22520v1,Multi-stage model predictive control for slug flow crystallizers using uncertainty-aware surrogate models,"['Collin R. Johnson', 'Stijn de Vries', 'Kerstin Wohlgemuth', 'Sergio Lucia']","This paper presents a novel dynamic model for slug flow crystallizers that addresses the challenges of spatial distribution without backmixing or diffusion, potentially enabling advanced model-based control. The developed model can accurately describe the main characteristics of slug flow crystallizers, including slug-to-slug variability but leads to a high computational complexity due to the consideration of partial differential equations and population balance equations. For that reason, the model cannot be directly used for process optimization and control. To solve this challenge, we propose two different approaches, conformalized quantile regression and Bayesian last layer neural networks, to develop surrogate models with uncertainty quantification capabilities. These surrogates output a prediction of the system states together with an uncertainty of these predictions to account for process variability and model uncertainty. We use the uncertainty of the predictions to formulate a robust model predictive control approach, enabling robust real-time advanced control of a slug flow crystallizer.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22520v1,paper present novel dynamic model slug flow crystallizers address challenge spatial distribution without backmixing diffusion potentially enabling advanced modelbased control developed model accurately describe main characteristic slug flow crystallizers including slugtoslug variability lead high computational complexity due consideration partial differential equation population balance equation reason model directly used process optimization control solve challenge propose two different approach conformalized quantile regression bayesian last layer neural network develop surrogate model uncertainty quantification capability surrogate output prediction system state together uncertainty prediction account process variability model uncertainty use uncertainty prediction formulate robust model predictive control approach enabling robust realtime advanced control slug flow crystallizer
2503.22517v1,Exploiting Mixture-of-Experts Redundancy Unlocks Multimodal Generative Abilities,"['Raman Dutt', 'Harleen Hanspal', 'Guoxuan Xia', 'Petru-Daniel Tudosiu', 'Alexander Black', 'Yongxin Yang', 'Steven McDonagh', 'Sarah Parisot']","In this work, we undertake the challenge of augmenting the existing generative capabilities of pre-trained text-only large language models (LLMs) with multi-modal generation capability while satisfying two core constraints: C1 preserving the preservation of original language generative capabilities with negligible performance degradation, and C2 adhering to a small parameter budget to learn the new modality, ensuring scalability and efficiency. In contrast to current approaches that add dedicated modules, thereby significantly increasing the parameter count, we propose a method that leverages the underutilized capacity inherent in deep models. Specifically, we exploit the parameter redundancy within Mixture-of-Experts (MoEs) as a source of additional capacity for learning a new modality, enabling better parameter efficiency (C1). Moreover, we preserve the original language generation capabilities by applying low-rank adaptation exclusively to the tokens of the new modality (C2). Furthermore, we introduce a novel parameter initialization scheme based on the Gromov-Wasserstein distance to improve convergence and training stability. Through an extensive analysis of the routing mechanism, we uncover the emergence of modality-specific pathways and decreased redundancy within the experts that can efficiently unlock multi-modal generative capabilities. Overall, our method can be seamlessly applied to a wide range of contemporary LLMs, providing a new pathway for transitioning from uni-modal to multi-modal architectures.",2025-03-28,"['cs.CL', 'cs.AI', 'cs.CV']",http://arxiv.org/pdf/2503.22517v1,work undertake challenge augmenting existing generative capability pretrained textonly large language model llm multimodal generation capability satisfying two core constraint c1 preserving preservation original language generative capability negligible performance degradation c2 adhering small parameter budget learn new modality ensuring scalability efficiency contrast current approach add dedicated module thereby significantly increasing parameter count propose method leverage underutilized capacity inherent deep model specifically exploit parameter redundancy within mixtureofexperts moes source additional capacity learning new modality enabling better parameter efficiency c1 moreover preserve original language generation capability applying lowrank adaptation exclusively token new modality c2 furthermore introduce novel parameter initialization scheme based gromovwasserstein distance improve convergence training stability extensive analysis routing mechanism uncover emergence modalityspecific pathway decreased redundancy within expert efficiently unlock multimodal generative capability overall method seamlessly applied wide range contemporary llm providing new pathway transitioning unimodal multimodal architecture
2503.22516v1,Assessing Foundation Models for Sea Ice Type Segmentation in Sentinel-1 SAR Imagery,"['Samira Alkaee Taleghan', 'Morteza Karimzadeh', 'Andrew P. Barrett', 'Walter N. Meier', 'Farnoush Banaei-Kashani']","Accurate segmentation of sea ice types is essential for mapping and operational forecasting of sea ice conditions for safe navigation and resource extraction in ice-covered waters, as well as for understanding polar climate processes. While deep learning methods have shown promise in automating sea ice segmentation, they often rely on extensive labeled datasets which require expert knowledge and are time-consuming to create. Recently, foundation models (FMs) have shown excellent results for segmenting remote sensing images by utilizing pre-training on large datasets using self-supervised techniques. However, their effectiveness for sea ice segmentation remains unexplored, especially given sea ice's complex structures, seasonal changes, and unique spectral signatures, as well as peculiar Synthetic Aperture Radar (SAR) imagery characteristics including banding and scalloping noise, and varying ice backscatter characteristics, which are often missing in standard remote sensing pre-training datasets. In particular, SAR images over polar regions are acquired using different modes than used to capture the images at lower latitudes by the same sensors that form training datasets for FMs. This study evaluates ten remote sensing FMs for sea ice type segmentation using Sentinel-1 SAR imagery, focusing on their seasonal and spatial generalization. Among the selected models, Prithvi-600M outperforms the baseline models, while CROMA achieves a very similar performance in F1-score. Our contributions include offering a systematic methodology for selecting FMs for sea ice data analysis, a comprehensive benchmarking study on performances of FMs for sea ice segmentation with tailored performance metrics, and insights into existing gaps and future directions for improving domain-specific models in polar applications using SAR data.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22516v1,accurate segmentation sea ice type essential mapping operational forecasting sea ice condition safe navigation resource extraction icecovered water well understanding polar climate process deep learning method shown promise automating sea ice segmentation often rely extensive labeled datasets require expert knowledge timeconsuming create recently foundation model fm shown excellent result segmenting remote sensing image utilizing pretraining large datasets using selfsupervised technique however effectiveness sea ice segmentation remains unexplored especially given sea ice complex structure seasonal change unique spectral signature well peculiar synthetic aperture radar sar imagery characteristic including banding scalloping noise varying ice backscatter characteristic often missing standard remote sensing pretraining datasets particular sar image polar region acquired using different mode used capture image lower latitude sensor form training datasets fm study evaluates ten remote sensing fm sea ice type segmentation using sentinel1 sar imagery focusing seasonal spatial generalization among selected model prithvi600m outperforms baseline model croma achieves similar performance f1score contribution include offering systematic methodology selecting fm sea ice data analysis comprehensive benchmarking study performance fm sea ice segmentation tailored performance metric insight existing gap future direction improving domainspecific model polar application using sar data
2503.22513v1,Masked Self-Supervised Pre-Training for Text Recognition Transformers on Large-Scale Datasets,"['Martin Kišš', 'Michal Hradiš']","Self-supervised learning has emerged as a powerful approach for leveraging large-scale unlabeled data to improve model performance in various domains. In this paper, we explore masked self-supervised pre-training for text recognition transformers. Specifically, we propose two modifications to the pre-training phase: progressively increasing the masking probability, and modifying the loss function to incorporate both masked and non-masked patches. We conduct extensive experiments using a dataset of 50M unlabeled text lines for pre-training and four differently sized annotated datasets for fine-tuning. Furthermore, we compare our pre-trained models against those trained with transfer learning, demonstrating the effectiveness of the self-supervised pre-training. In particular, pre-training consistently improves the character error rate of models, in some cases up to 30 % relatively. It is also on par with transfer learning but without relying on extra annotated text lines.",2025-03-28,"['cs.CV', 'cs.AI', 'cs.LG']",http://arxiv.org/pdf/2503.22513v1,selfsupervised learning emerged powerful approach leveraging largescale unlabeled data improve model performance various domain paper explore masked selfsupervised pretraining text recognition transformer specifically propose two modification pretraining phase progressively increasing masking probability modifying loss function incorporate masked nonmasked patch conduct extensive experiment using dataset 50m unlabeled text line pretraining four differently sized annotated datasets finetuning furthermore compare pretrained model trained transfer learning demonstrating effectiveness selfsupervised pretraining particular pretraining consistently improves character error rate model case 30 relatively also par transfer learning without relying extra annotated text line
2503.22512v1,Unlocking LLM Repair Capabilities in Low-Resource Programming Languages Through Cross-Language Translation and Multi-Agent Refinement,"['Wenqiang Luo', 'Jacky Wai Keung', 'Boyang Yang', 'Tegawende F. Bissyande', 'Haoye Tian', 'Bach Le']","Recent advances in leveraging LLMs for APR have demonstrated impressive capabilities in fixing software defects. However, current LLM-based approaches predominantly focus on mainstream programming languages like Java and Python, neglecting less prevalent but emerging languages such as Rust due to expensive training resources, limited datasets, and insufficient community support. This narrow focus creates a significant gap in repair capabilities across the programming language spectrum, where the full potential of LLMs for comprehensive multilingual program repair remains largely unexplored. To address this limitation, we introduce a novel cross-language program repair approach LANTERN that leverages LLMs' differential proficiency across languages through a multi-agent iterative repair paradigm. Our technique strategically translates defective code from languages where LLMs exhibit weaker repair capabilities to languages where they demonstrate stronger performance, without requiring additional training. A key innovation of our approach is an LLM-based decision-making system that dynamically selects optimal target languages based on bug characteristics and continuously incorporates feedback from previous repair attempts. We evaluate our method on xCodeEval, a comprehensive multilingual benchmark comprising 5,068 bugs across 11 programming languages. Results demonstrate significant enhancement in repair effectiveness, particularly for underrepresented languages, with Rust showing a 22.09% improvement in Pass@10 metrics. Our research provides the first empirical evidence that cross-language translation significantly expands the repair capabilities of LLMs and effectively bridges the performance gap between programming languages with different levels of popularity, opening new avenues for truly language-agnostic automated program repair.",2025-03-28,['cs.SE'],http://arxiv.org/pdf/2503.22512v1,recent advance leveraging llm apr demonstrated impressive capability fixing software defect however current llmbased approach predominantly focus mainstream programming language like java python neglecting le prevalent emerging language rust due expensive training resource limited datasets insufficient community support narrow focus creates significant gap repair capability across programming language spectrum full potential llm comprehensive multilingual program repair remains largely unexplored address limitation introduce novel crosslanguage program repair approach lantern leverage llm differential proficiency across language multiagent iterative repair paradigm technique strategically translates defective code language llm exhibit weaker repair capability language demonstrate stronger performance without requiring additional training key innovation approach llmbased decisionmaking system dynamically selects optimal target language based bug characteristic continuously incorporates feedback previous repair attempt evaluate method xcodeeval comprehensive multilingual benchmark comprising 5068 bug across 11 programming language result demonstrate significant enhancement repair effectiveness particularly underrepresented language rust showing 2209 improvement pass10 metric research provides first empirical evidence crosslanguage translation significantly expands repair capability llm effectively bridge performance gap programming language different level popularity opening new avenue truly languageagnostic automated program repair
2503.22510v1,Automated UX Insights from User Research Videos by Integrating Facial Emotion and Text Sentiment,"['Simran Kaur Ghatoray', 'Yongmin Li']","Emotion recognition technology has been studied from the past decade. With its growing importance and applications such as customer service, medical, education, etc., this research study aims to explore its potential and importance in the field of User experience evaluation. Recognizing and keeping track of user emotions in user research video is important to understand user needs and expectations from a service/product. Little research has been done that focuses on automating emotion extraction from a video where more than one modality has been incorporated in the field of UX. The study aims at implementing different modalities such as facial emotion recognition, speech-to-text and text-based emotion recognition for capturing emotional nuances from a user research video and extract meaningful actionable insights. For selection of facial emotion recognition model, 10 pre-trained models were evaluated on three benchmark datasets i.e. FER-2013, AffectNet and CK+, selecting the model with most generalization ability. To extract speech and convert to text, OpenAI's Whisper model was implemented and finally the emotions from text were recognized using a pre-trained model available at HuggingFace website having an evaluation accuracy more than 95%. The study also integrates the gathered data using temporal alignment and fusion for deeper and contextual insights. The study further demonstrates a way of automating data analysis through PandasAI Python library where OpenAI's GPT-4o model was implemented along with a discussion on other possible solutions. This study is an attempt to demonstrate a proof of concept where automated meaningful insights are extracted from a video based on user emotions.",2025-03-28,['cs.HC'],http://arxiv.org/pdf/2503.22510v1,emotion recognition technology studied past decade growing importance application customer service medical education etc research study aim explore potential importance field user experience evaluation recognizing keeping track user emotion user research video important understand user need expectation serviceproduct little research done focus automating emotion extraction video one modality incorporated field ux study aim implementing different modality facial emotion recognition speechtotext textbased emotion recognition capturing emotional nuance user research video extract meaningful actionable insight selection facial emotion recognition model 10 pretrained model evaluated three benchmark datasets ie fer2013 affectnet ck selecting model generalization ability extract speech convert text openais whisper model implemented finally emotion text recognized using pretrained model available huggingface website evaluation accuracy 95 study also integrates gathered data using temporal alignment fusion deeper contextual insight study demonstrates way automating data analysis pandasai python library openais gpt4o model implemented along discussion possible solution study attempt demonstrate proof concept automated meaningful insight extracted video based user emotion
2503.22508v1,Improving Low-Resource Retrieval Effectiveness using Zero-Shot Linguistic Similarity Transfer,"['Andreas Chari', 'Sean MacAvaney', 'Iadh Ounis']","Globalisation and colonisation have led the vast majority of the world to use only a fraction of languages, such as English and French, to communicate, excluding many others. This has severely affected the survivability of many now-deemed vulnerable or endangered languages, such as Occitan and Sicilian. These languages often share some characteristics, such as elements of their grammar and lexicon, with other high-resource languages, e.g. French or Italian. They can be clustered into groups of language varieties with various degrees of mutual intelligibility. Current search systems are not usually trained on many of these low-resource varieties, leading search users to express their needs in a high-resource language instead. This problem is further complicated when most information content is expressed in a high-resource language, inhibiting even more retrieval in low-resource languages. We show that current search systems are not robust across language varieties, severely affecting retrieval effectiveness. Therefore, it would be desirable for these systems to leverage the capabilities of neural models to bridge the differences between these varieties. This can allow users to express their needs in their low-resource variety and retrieve the most relevant documents in a high-resource one. To address this, we propose fine-tuning neural rankers on pairs of language varieties, thereby exposing them to their linguistic similarities. We find that this approach improves the performance of the varieties upon which the models were directly trained, thereby regularising these models to generalise and perform better even on unseen language variety pairs. We also explore whether this approach can transfer across language families and observe mixed results that open doors for future research.",2025-03-28,['cs.IR'],http://arxiv.org/pdf/2503.22508v1,globalisation colonisation led vast majority world use fraction language english french communicate excluding many others severely affected survivability many nowdeemed vulnerable endangered language occitan sicilian language often share characteristic element grammar lexicon highresource language eg french italian clustered group language variety various degree mutual intelligibility current search system usually trained many lowresource variety leading search user express need highresource language instead problem complicated information content expressed highresource language inhibiting even retrieval lowresource language show current search system robust across language variety severely affecting retrieval effectiveness therefore would desirable system leverage capability neural model bridge difference variety allow user express need lowresource variety retrieve relevant document highresource one address propose finetuning neural ranker pair language variety thereby exposing linguistic similarity find approach improves performance variety upon model directly trained thereby regularising model generalise perform better even unseen language variety pair also explore whether approach transfer across language family observe mixed result open door future research
2503.22506v1,Design and Analysis of a Robust Control System for Triple Inverted Pendulum Stabilization,"['Tohid Kargar Tasooji', 'Sakineh Khodadadi']","The design of robust controllers for triple inverted pendulum systems presents significant challenges due to their inherent instability and nonlinear dynamics. Furthermore, uncertainties in system parameters further complicate the control design. This paper investigates a robust control strategy for triple inverted pendulums under parameter uncertainty. Two control approaches, namely the $H_\infty$ controller and the $\mu$-synthesis controller, are compared in terms of their ability to achieve reference tracking and disturbance rejection. Simulation results demonstrate that the $H_\infty$ controller provides superior transient performance, making it a promising solution for the robust stabilization of such complex systems.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22506v1,design robust controller triple inverted pendulum system present significant challenge due inherent instability nonlinear dynamic furthermore uncertainty system parameter complicate control design paper investigates robust control strategy triple inverted pendulum parameter uncertainty two control approach namely hinfty controller musynthesis controller compared term ability achieve reference tracking disturbance rejection simulation result demonstrate hinfty controller provides superior transient performance making promising solution robust stabilization complex system
2503.22503v1,Cross-Technology Generalization in Synthesized Speech Detection: Evaluating AST Models with Modern Voice Generators,"['Andrew Ustinov', 'Matey Yordanov', 'Andrei Kuchma', 'Mikhail Bychkov']","This paper evaluates the Audio Spectrogram Transformer (AST) architecture for synthesized speech detection, with focus on generalization across modern voice generation technologies. Using differentiated augmentation strategies, the model achieves 0.91% EER overall when tested against ElevenLabs, NotebookLM, and Minimax AI voice generators. Notably, after training with only 102 samples from a single technology, the model demonstrates strong cross-technology generalization, achieving 3.3% EER on completely unseen voice generators. This work establishes benchmarks for rapid adaptation to emerging synthesis technologies and provides evidence that transformer-based architectures can identify common artifacts across different neural voice synthesis methods, contributing to more robust speech verification systems.",2025-03-28,"['cs.SD', 'cs.CR', 'eess.AS']",http://arxiv.org/pdf/2503.22503v1,paper evaluates audio spectrogram transformer ast architecture synthesized speech detection focus generalization across modern voice generation technology using differentiated augmentation strategy model achieves 091 eer overall tested elevenlabs notebooklm minimax ai voice generator notably training 102 sample single technology model demonstrates strong crosstechnology generalization achieving 33 eer completely unseen voice generator work establishes benchmark rapid adaptation emerging synthesis technology provides evidence transformerbased architecture identify common artifact across different neural voice synthesis method contributing robust speech verification system
2503.22498v1,Learnable cut flow,"['Jing Li', 'Hao Sun']","Neural networks have emerged as a powerful paradigm for tasks in high energy physics, yet their opaque training process renders them as a black box. In contrast, the traditional cut flow method offers simplicity and interpretability but demands human effort to identify optimal boundaries. To merge the strengths of both approaches, we propose the Learnable Cut Flow (LCF), a neural network that transforms the traditional cut selection into a fully differentiable, data-driven process. LCF implements two cut strategies-parallel, where observable distributions are treated independently, and sequential, where prior cuts shape subsequent ones-to flexibly determine optimal boundaries. Building on this, we introduce the Learnable Importance, a metric that quantifies feature importance and adjusts their contributions to the loss accordingly, offering model-driven insights unlike ad-hoc metrics. To ensure differentiability, a modified loss function replaces hard cuts with mask operations, preserving data shape throughout the training process. LCF is tested on six varied mock datasets and a realistic diboson vs. QCD dataset. Results demonstrate that LCF (1) accurately learns cut boundaries across typical feature distributions in both parallel and sequential strategies, (2) assigns higher importance to discriminative features with minimal overlap, (3) handles redundant or correlated features robustly, and (4) performs effectively in real-world scenarios. In diboson dataset, LCF initially underperforms boosted decision trees and multiplayer perceptrons when using all observables. However, pruning less critical features-guided by learned importance-boosts its performance to match or exceed these baselines. LCF bridges the gap between traditional cut flow method and modern black-box neural networks, delivering actionable insights into the training process and feature importance.",2025-03-28,"['cs.LG', 'hep-ph']",http://arxiv.org/pdf/2503.22498v1,neural network emerged powerful paradigm task high energy physic yet opaque training process render black box contrast traditional cut flow method offer simplicity interpretability demand human effort identify optimal boundary merge strength approach propose learnable cut flow lcf neural network transforms traditional cut selection fully differentiable datadriven process lcf implement two cut strategiesparallel observable distribution treated independently sequential prior cut shape subsequent onesto flexibly determine optimal boundary building introduce learnable importance metric quantifies feature importance adjusts contribution loss accordingly offering modeldriven insight unlike adhoc metric ensure differentiability modified loss function replaces hard cut mask operation preserving data shape throughout training process lcf tested six varied mock datasets realistic diboson v qcd dataset result demonstrate lcf 1 accurately learns cut boundary across typical feature distribution parallel sequential strategy 2 assigns higher importance discriminative feature minimal overlap 3 handle redundant correlated feature robustly 4 performs effectively realworld scenario diboson dataset lcf initially underperforms boosted decision tree multiplayer perceptrons using observables however pruning le critical featuresguided learned importanceboosts performance match exceed baseline lcf bridge gap traditional cut flow method modern blackbox neural network delivering actionable insight training process feature importance
2503.22496v1,Scenario Dreamer: Vectorized Latent Diffusion for Generating Driving Simulation Environments,"['Luke Rowe', 'Roger Girgis', 'Anthony Gosselin', 'Liam Paull', 'Christopher Pal', 'Felix Heide']","We introduce Scenario Dreamer, a fully data-driven generative simulator for autonomous vehicle planning that generates both the initial traffic scene - comprising a lane graph and agent bounding boxes - and closed-loop agent behaviours. Existing methods for generating driving simulation environments encode the initial traffic scene as a rasterized image and, as such, require parameter-heavy networks that perform unnecessary computation due to many empty pixels in the rasterized scene. Moreover, we find that existing methods that employ rule-based agent behaviours lack diversity and realism. Scenario Dreamer instead employs a novel vectorized latent diffusion model for initial scene generation that directly operates on the vectorized scene elements and an autoregressive Transformer for data-driven agent behaviour simulation. Scenario Dreamer additionally supports scene extrapolation via diffusion inpainting, enabling the generation of unbounded simulation environments. Extensive experiments show that Scenario Dreamer outperforms existing generative simulators in realism and efficiency: the vectorized scene-generation base model achieves superior generation quality with around 2x fewer parameters, 6x lower generation latency, and 10x fewer GPU training hours compared to the strongest baseline. We confirm its practical utility by showing that reinforcement learning planning agents are more challenged in Scenario Dreamer environments than traditional non-generative simulation environments, especially on long and adversarial driving environments.",2025-03-28,"['cs.RO', 'cs.CV']",http://arxiv.org/pdf/2503.22496v1,introduce scenario dreamer fully datadriven generative simulator autonomous vehicle planning generates initial traffic scene comprising lane graph agent bounding box closedloop agent behaviour existing method generating driving simulation environment encode initial traffic scene rasterized image require parameterheavy network perform unnecessary computation due many empty pixel rasterized scene moreover find existing method employ rulebased agent behaviour lack diversity realism scenario dreamer instead employ novel vectorized latent diffusion model initial scene generation directly operates vectorized scene element autoregressive transformer datadriven agent behaviour simulation scenario dreamer additionally support scene extrapolation via diffusion inpainting enabling generation unbounded simulation environment extensive experiment show scenario dreamer outperforms existing generative simulator realism efficiency vectorized scenegeneration base model achieves superior generation quality around 2x fewer parameter 6x lower generation latency 10x fewer gpu training hour compared strongest baseline confirm practical utility showing reinforcement learning planning agent challenged scenario dreamer environment traditional nongenerative simulation environment especially long adversarial driving environment
2503.22492v1,Reaching Classicality through Transitive Closure,"['Quentin Blomet', 'Bruno Da Ré']","Recently, arXiv:2312.16035 showed that all logics based on Boolean Normal monotonic three-valued schemes coincide with classical logic when defined using a strict-tolerant standard ($\mathbf{st}$). Conversely, they proved that under a tolerant-strict standard ($\mathbf{ts}$), the resulting logics are all empty. Building on these results, we show that classical logic can be obtained by closing under transitivity the union of two logics defined over (potentially different) Boolean normal monotonic schemes, using a strict-strict standard ($\mathbf{ss}$) for one and a tolerant-tolerant standard ($\mathbf{tt}$) for the other, with the first of these logics being paracomplete and the other being paraconsistent. We then identify a notion dual to transitivity that allows us to characterize the logic $\mathsf{TS}$ as the dual transitive closure of the intersection of any two logics defined over (potentially different) Boolean normal monotonic schemes, using an $\mathbf{ss}$ standard for one and a $\mathbf{tt}$ standard for the other. Finally, we expand on the abstract relations between the transitive closure and dual transitive closure operations, showing that they give rise to lattice operations that precisely capture how the logics discussed relate to one another.",2025-03-28,"['math.LO', 'cs.LO']",http://arxiv.org/pdf/2503.22492v1,recently arxiv231216035 showed logic based boolean normal monotonic threevalued scheme coincide classical logic defined using stricttolerant standard mathbfst conversely proved tolerantstrict standard mathbfts resulting logic empty building result show classical logic obtained closing transitivity union two logic defined potentially different boolean normal monotonic scheme using strictstrict standard mathbfss one toleranttolerant standard mathbftt first logic paracomplete paraconsistent identify notion dual transitivity allows u characterize logic mathsfts dual transitive closure intersection two logic defined potentially different boolean normal monotonic scheme using mathbfss standard one mathbftt standard finally expand abstract relation transitive closure dual transitive closure operation showing give rise lattice operation precisely capture logic discussed relate one another
2503.22489v1,Energy-efficient UAV movement and user-UAV association in multi-UAV networks,"['Subhadip Ghosh', 'Priyadarshi Mukherjee', 'Sasthi C. Ghosh']","These days, unmanned aerial vehicle (UAV)-based millimeter wave (mmWave) communication systems have drawn a lot of attention due to the increasing demand for faster data rates. Given the susceptibility of mmWave signals to obstacles and high propagation loss of mmWaves, ensuring line-of-sight (LoS) connectivity is critical for maintaining robust and efficient communication. Furthermore, UAVs have limited power resource and limited capacity in terms of number of users it can serve. Most significantly different users have different delay requirements and they keep moving while interacting with the UAVs. In this paper, first, we have provided an efficient solution for the optimal movement of the UAVs, by taking into account the energy efficiency of the UAVs as well as the mobility and delay priority of the users. Next, we have proposed a greedy solution for the optimal user-UAV assignment. After that, the numerical results show how well the suggested solution performs in comparison to the current benchmarks in terms of delay suffered by the users, number of unserved users, and energy efficiency of the UAVs.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22489v1,day unmanned aerial vehicle uavbased millimeter wave mmwave communication system drawn lot attention due increasing demand faster data rate given susceptibility mmwave signal obstacle high propagation loss mmwaves ensuring lineofsight los connectivity critical maintaining robust efficient communication furthermore uavs limited power resource limited capacity term number user serve significantly different user different delay requirement keep moving interacting uavs paper first provided efficient solution optimal movement uavs taking account energy efficiency uavs well mobility delay priority user next proposed greedy solution optimal useruav assignment numerical result show well suggested solution performs comparison current benchmark term delay suffered user number unserved user energy efficiency uavs
2503.22487v1,"A Multi-Objective Simultaneous Routing, Facility Location and Allocation Model for Earthquake Emergency Logistics","['Sakineh Khodadadi', 'Tohid Kargar Tasooji', 'Afshin Shariat-Mohayman', 'Navid Kalantari']","Emergency preparedness reduces the severity and impact of major disasters. In the case of earthquakes, a rapid and efficient emergency response is essential to reduce the number of fatalities. Therefore, the design and planning of an adequate emergency transportation network are crucial in earthquake-prone locations.   In the context of emergency transportation modeling, the aim of emergency routing is to find the network with the minimum length that can provide access between the maximum number of Emergency Response Centers (ERCs) and damaged areas. Meanwhile, the goal of the facility location and allocation problem is to optimize the placement of temporary hospitals to increase coverage and accessibility, particularly in remote or severely impacted areas.   This paper proposes a multi-objective, robust, multi-modal, and multi-time-period optimization problem that simultaneously optimizes routing, facility location, and hospital allocation. The objective function is to minimize unmet commodity demand, unserved injuries, and economic costs. We adopt a fuzzy goal programming approach to solve the multi-objective simultaneous routing, facility location, and allocation model.",2025-03-28,"['eess.SY', 'cs.SY']",http://arxiv.org/pdf/2503.22487v1,emergency preparedness reduces severity impact major disaster case earthquake rapid efficient emergency response essential reduce number fatality therefore design planning adequate emergency transportation network crucial earthquakeprone location context emergency transportation modeling aim emergency routing find network minimum length provide access maximum number emergency response center ercs damaged area meanwhile goal facility location allocation problem optimize placement temporary hospital increase coverage accessibility particularly remote severely impacted area paper proposes multiobjective robust multimodal multitimeperiod optimization problem simultaneously optimizes routing facility location hospital allocation objective function minimize unmet commodity demand unserved injury economic cost adopt fuzzy goal programming approach solve multiobjective simultaneous routing facility location allocation model
2503.22486v1,Movable Antenna Enhanced Downlink Multi-User Integrated Sensing and Communication System,"['Yanze Han', 'Min Li', 'Xingyu Zhao', 'Ming-Min Zhao', 'Min-Jian Zhao']","This work investigates the potential of exploiting movable antennas (MAs) to enhance the performance of a multi-user downlink integrated sensing and communication (ISAC) system. Specifically, we formulate an optimization problem to maximize the transmit beampattern gain for sensing while simultaneously meeting each user's communication requirement by jointly optimizing antenna positions and beamforming design. The problem formulated is highly non-convex and involves multivariate-coupled constraints. To address these challenges, we introduce a series of auxiliary random variables and transform the original problem into an augmented Lagrangian problem. A double-loop algorithm based on a penalty dual decomposition framework is then developed to solve the problem. Numerical results validate the effectiveness of the proposed design, demonstrating its superiority over MA designs based on successive convex approximation optimization and other baseline approaches in ISAC systems. The results also highlight the advantages of MAs in achieving better sensing performance and improved beam control, especially for sparse arrays with large apertures.",2025-03-28,"['cs.IT', 'eess.SP', 'math.IT']",http://arxiv.org/pdf/2503.22486v1,work investigates potential exploiting movable antenna ma enhance performance multiuser downlink integrated sensing communication isac system specifically formulate optimization problem maximize transmit beampattern gain sensing simultaneously meeting user communication requirement jointly optimizing antenna position beamforming design problem formulated highly nonconvex involves multivariatecoupled constraint address challenge introduce series auxiliary random variable transform original problem augmented lagrangian problem doubleloop algorithm based penalty dual decomposition framework developed solve problem numerical result validate effectiveness proposed design demonstrating superiority design based successive convex approximation optimization baseline approach isac system result also highlight advantage ma achieving better sensing performance improved beam control especially sparse array large aperture
2503.22485v1,SPDNet: Seasonal-Periodic Decomposition Network for Advanced Residential Demand Forecasting,"['Reza Nematirad', 'Anil Pahwa', 'Balasubramaniam Natarajan']","Residential electricity demand forecasting is critical for efficient energy management and grid stability. Accurate predictions enable utility companies to optimize planning and operations. However, real-world residential electricity demand data often exhibit intricate temporal variability, including multiple seasonalities, periodicities, and abrupt fluctuations, which pose significant challenges for forecasting models. Previous models that rely on statistical methods, recurrent, convolutional neural networks, and transformers often struggle to capture these intricate temporal dynamics. To address these challenges, we propose the Seasonal-Periodic Decomposition Network (SPDNet), a novel deep learning framework consisting of two main modules. The first is the Seasonal-Trend Decomposition Module (STDM), which decomposes the input data into trend, seasonal, and residual components. The second is the Periodical Decomposition Module (PDM), which employs the Fast Fourier Transform to identify the dominant periods. For each dominant period, 1D input data is reshaped into a 2D tensor, where rows represent periods and columns correspond to frequencies. The 2D representations are then processed through three submodules: a 1D convolution to capture sharp fluctuations, a transformer-based encoder to model global patterns, and a 2D convolution to capture interactions between periods. Extensive experiments conducted on real-world residential electricity load data demonstrate that SPDNet outperforms traditional and advanced models in both forecasting accuracy and computational efficiency. The code is available in this repository: https://github.com/Tims2D/SPDNet.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22485v1,residential electricity demand forecasting critical efficient energy management grid stability accurate prediction enable utility company optimize planning operation however realworld residential electricity demand data often exhibit intricate temporal variability including multiple seasonalities periodicity abrupt fluctuation pose significant challenge forecasting model previous model rely statistical method recurrent convolutional neural network transformer often struggle capture intricate temporal dynamic address challenge propose seasonalperiodic decomposition network spdnet novel deep learning framework consisting two main module first seasonaltrend decomposition module stdm decomposes input data trend seasonal residual component second periodical decomposition module pdm employ fast fourier transform identify dominant period dominant period 1d input data reshaped 2d tensor row represent period column correspond frequency 2d representation processed three submodules 1d convolution capture sharp fluctuation transformerbased encoder model global pattern 2d convolution capture interaction period extensive experiment conducted realworld residential electricity load data demonstrate spdnet outperforms traditional advanced model forecasting accuracy computational efficiency code available repository httpsgithubcomtims2dspdnet
2503.22480v1,Probabilistic Uncertain Reward Model: A Natural Generalization of Bradley-Terry Reward Model,"['Wangtao Sun', 'Xiang Cheng', 'Xing Yu', 'Haotian Xu', 'Zhao Yang', 'Shizhu He', 'Jun Zhao', 'Kang Liu']","Reinforcement Learning from Human Feedback (RLHF) has emerged as a critical technique for training large language models. However, reward hacking-a phenomenon where models exploit flaws in the reward model-remains a significant barrier to achieving robust and scalable intelligence through long-term training. Existing studies have proposed uncertain reward model to address reward hacking, however, they often lack systematic or theoretical foundations, failing to model the uncertainty intrinsically emerging from preference data. In this paper, we propose the Probabilistic Uncertain Reward Model (PURM), a natural generalization of the classical Bradley-Terry reward model. PURM learns reward distributions directly from preference data and quantifies per-sample uncertainty via the average overlap area between reward distributions. To mitigate reward hacking, we further introduce an uncertainty-aware penalty into Proximal Policy Optimization (PPO), which leverages the learned uncertainty to dynamically balance reward optimization and exploration. We propose a lightweight and easy-to-use implementation of PURM. Experiments demonstrate that PURM significantly delays the onset of reward hacking while improving final reward performance, outperforming baseline methods in both stability and effectiveness.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22480v1,reinforcement learning human feedback rlhf emerged critical technique training large language model however reward hackinga phenomenon model exploit flaw reward modelremains significant barrier achieving robust scalable intelligence longterm training existing study proposed uncertain reward model address reward hacking however often lack systematic theoretical foundation failing model uncertainty intrinsically emerging preference data paper propose probabilistic uncertain reward model purm natural generalization classical bradleyterry reward model purm learns reward distribution directly preference data quantifies persample uncertainty via average overlap area reward distribution mitigate reward hacking introduce uncertaintyaware penalty proximal policy optimization ppo leverage learned uncertainty dynamically balance reward optimization exploration propose lightweight easytouse implementation purm experiment demonstrate purm significantly delay onset reward hacking improving final reward performance outperforming baseline method stability effectiveness
2503.22478v1,Almost Bayesian: The Fractal Dynamics of Stochastic Gradient Descent,"['Max Hennick', 'Stijn De Baerdemacker']","We show that the behavior of stochastic gradient descent is related to Bayesian statistics by showing that SGD is effectively diffusion on a fractal landscape, where the fractal dimension can be accounted for in a purely Bayesian way. By doing this we show that SGD can be regarded as a modified Bayesian sampler which accounts for accessibility constraints induced by the fractal structure of the loss landscape. We verify our results experimentally by examining the diffusion of weights during training. These results offer insight into the factors which determine the learning process, and seemingly answer the question of how SGD and purely Bayesian sampling are related.",2025-03-28,"['cs.LG', 'cs.AI', 'math.OC']",http://arxiv.org/pdf/2503.22478v1,show behavior stochastic gradient descent related bayesian statistic showing sgd effectively diffusion fractal landscape fractal dimension accounted purely bayesian way show sgd regarded modified bayesian sampler account accessibility constraint induced fractal structure loss landscape verify result experimentally examining diffusion weight training result offer insight factor determine learning process seemingly answer question sgd purely bayesian sampling related
2503.22475v1,DeepOFormer: Deep Operator Learning with Domain-informed Features for Fatigue Life Prediction,"['Chenyang Li', 'Tanmay Sunil Kapure', 'Prokash Chandra Roy', 'Zhengtao Gan', 'Bo Shen']","Fatigue life characterizes the duration a material can function before failure under specific environmental conditions, and is traditionally assessed using stress-life (S-N) curves. While machine learning and deep learning offer promising results for fatigue life prediction, they face the overfitting challenge because of the small size of fatigue experimental data in specific materials. To address this challenge, we propose, DeepOFormer, by formulating S-N curve prediction as an operator learning problem. DeepOFormer improves the deep operator learning framework with a transformer-based encoder and a mean L2 relative error loss function. We also consider Stussi, Weibull, and Pascual and Meeker (PM) features as domain-informed features. These features are motivated by empirical fatigue models. To evaluate the performance of our DeepOFormer, we compare it with different deep learning models and XGBoost on a dataset with 54 S-N curves of aluminum alloys. With seven different aluminum alloys selected for testing, our DeepOFormer achieves an R2 of 0.9515, a mean absolute error of 0.2080, and a mean relative error of 0.5077, significantly outperforming state-of-the-art deep/machine learning methods including DeepONet, TabTransformer, and XGBoost, etc. The results highlight that our Deep0Former integrating with domain-informed features substantially improves prediction accuracy and generalization capabilities for fatigue life prediction in aluminum alloys.",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22475v1,fatigue life characterizes duration material function failure specific environmental condition traditionally assessed using stresslife sn curve machine learning deep learning offer promising result fatigue life prediction face overfitting challenge small size fatigue experimental data specific material address challenge propose deepoformer formulating sn curve prediction operator learning problem deepoformer improves deep operator learning framework transformerbased encoder mean l2 relative error loss function also consider stussi weibull pascual meeker pm feature domaininformed feature feature motivated empirical fatigue model evaluate performance deepoformer compare different deep learning model xgboost dataset 54 sn curve aluminum alloy seven different aluminum alloy selected testing deepoformer achieves r2 09515 mean absolute error 02080 mean relative error 05077 significantly outperforming stateoftheart deepmachine learning method including deeponet tabtransformer xgboost etc result highlight deep0former integrating domaininformed feature substantially improves prediction accuracy generalization capability fatigue life prediction aluminum alloy
2503.22473v1,WorkTeam: Constructing Workflows from Natural Language with Multi-Agents,"['Hanchao Liu', 'Rongjun Li', 'Weimin Xiong', 'Ziyu Zhou', 'Wei Peng']","Workflows play a crucial role in enhancing enterprise efficiency by orchestrating complex processes with multiple tools or components. However, hand-crafted workflow construction requires expert knowledge, presenting significant technical barriers. Recent advancements in Large Language Models (LLMs) have improved the generation of workflows from natural language instructions (aka NL2Workflow), yet existing single LLM agent-based methods face performance degradation on complex tasks due to the need for specialized knowledge and the strain of task-switching. To tackle these challenges, we propose WorkTeam, a multi-agent NL2Workflow framework comprising a supervisor, orchestrator, and filler agent, each with distinct roles that collaboratively enhance the conversion process. As there are currently no publicly available NL2Workflow benchmarks, we also introduce the HW-NL2Workflow dataset, which includes 3,695 real-world business samples for training and evaluation. Experimental results show that our approach significantly increases the success rate of workflow construction, providing a novel and effective solution for enterprise NL2Workflow services.",2025-03-28,['cs.CL'],http://arxiv.org/pdf/2503.22473v1,workflow play crucial role enhancing enterprise efficiency orchestrating complex process multiple tool component however handcrafted workflow construction requires expert knowledge presenting significant technical barrier recent advancement large language model llm improved generation workflow natural language instruction aka nl2workflow yet existing single llm agentbased method face performance degradation complex task due need specialized knowledge strain taskswitching tackle challenge propose workteam multiagent nl2workflow framework comprising supervisor orchestrator filler agent distinct role collaboratively enhance conversion process currently publicly available nl2workflow benchmark also introduce hwnl2workflow dataset includes 3695 realworld business sample training evaluation experimental result show approach significantly increase success rate workflow construction providing novel effective solution enterprise nl2workflow service
2503.22462v1,SemAlign3D: Semantic Correspondence between RGB-Images through Aligning 3D Object-Class Representations,"['Krispin Wandel', 'Hesheng Wang']","Semantic correspondence made tremendous progress through the recent advancements of large vision models (LVM). While these LVMs have been shown to reliably capture local semantics, the same can currently not be said for capturing global geometric relationships between semantic object regions. This problem leads to unreliable performance for semantic correspondence between images with extreme view variation. In this work, we aim to leverage monocular depth estimates to capture these geometric relationships for more robust and data-efficient semantic correspondence. First, we introduce a simple but effective method to build 3D object-class representations from monocular depth estimates and LVM features using a sparsely annotated image correspondence dataset. Second, we formulate an alignment energy that can be minimized using gradient descent to obtain an alignment between the 3D object-class representation and the object-class instance in the input RGB-image. Our method achieves state-of-the-art matching accuracy in multiple categories on the challenging SPair-71k dataset, increasing the PCK@0.1 score by more than 10 points on three categories and overall by 3.3 points from 85.6% to 88.9%. Additional resources and code are available at https://dub.sh/semalign3d.",2025-03-28,['cs.CV'],http://arxiv.org/pdf/2503.22462v1,semantic correspondence made tremendous progress recent advancement large vision model lvm lvms shown reliably capture local semantics currently said capturing global geometric relationship semantic object region problem lead unreliable performance semantic correspondence image extreme view variation work aim leverage monocular depth estimate capture geometric relationship robust dataefficient semantic correspondence first introduce simple effective method build 3d objectclass representation monocular depth estimate lvm feature using sparsely annotated image correspondence dataset second formulate alignment energy minimized using gradient descent obtain alignment 3d objectclass representation objectclass instance input rgbimage method achieves stateoftheart matching accuracy multiple category challenging spair71k dataset increasing pck01 score 10 point three category overall 33 point 856 889 additional resource code available httpsdubshsemalign3d
2503.22459v1,Control of Humanoid Robots with Parallel Mechanisms using Kinematic Actuation Models,"['Victor Lutz', 'Ludovic de Matteïs', 'Virgile Batto', 'Nicolas Mansard']","Inspired by the mechanical design of Cassie, several recently released humanoid robots are using actuator configuration in which the motor is displaced from the joint location to optimize the leg inertia. This in turn induces a non linearity in the reduction ratio of the transmission which is often neglected when computing the robot motion (e.g. by trajectory optimization or reinforcement learning) and only accounted for at control time. This paper proposes an analytical method to efficiently handle this non-linearity. Using this actuation model, we demonstrate that we can leverage the dynamic abilities of the non-linear transmission while only modeling the inertia of the main serial chain of the leg, without approximating the motor capabilities nor the joint range. Based on analytical inverse kinematics, our method does not need any numerical routines dedicated to the closed-kinematics actuation, hence leading to very efficient computations. Our study focuses on two mechanisms widely used in recent humanoid robots; the four bar knee linkage as well as a parallel 2 DoF ankle mechanism. We integrate these models inside optimization based (DDP) and learning (PPO) control approaches. A comparison of our model against a simplified model that completely neglects closed chains is then shown in simulation.",2025-03-28,"['cs.RO', 'cs.SY', 'eess.SY']",http://arxiv.org/pdf/2503.22459v1,inspired mechanical design cassie several recently released humanoid robot using actuator configuration motor displaced joint location optimize leg inertia turn induces non linearity reduction ratio transmission often neglected computing robot motion eg trajectory optimization reinforcement learning accounted control time paper proposes analytical method efficiently handle nonlinearity using actuation model demonstrate leverage dynamic ability nonlinear transmission modeling inertia main serial chain leg without approximating motor capability joint range based analytical inverse kinematics method need numerical routine dedicated closedkinematics actuation hence leading efficient computation study focus two mechanism widely used recent humanoid robot four bar knee linkage well parallel 2 dof ankle mechanism integrate model inside optimization based ddp learning ppo control approach comparison model simplified model completely neglect closed chain shown simulation
2503.22458v1,Evaluating LLM-based Agents for Multi-Turn Conversations: A Survey,"['Shengyue Guan', 'Haoyi Xiong', 'Jindong Wang', 'Jiang Bian', 'Bin Zhu', 'Jian-guang Lou']","This survey examines evaluation methods for large language model (LLM)-based agents in multi-turn conversational settings. Using a PRISMA-inspired framework, we systematically reviewed nearly 250 scholarly sources, capturing the state of the art from various venues of publication, and establishing a solid foundation for our analysis. Our study offers a structured approach by developing two interrelated taxonomy systems: one that defines \emph{what to evaluate} and another that explains \emph{how to evaluate}. The first taxonomy identifies key components of LLM-based agents for multi-turn conversations and their evaluation dimensions, including task completion, response quality, user experience, memory and context retention, as well as planning and tool integration. These components ensure that the performance of conversational agents is assessed in a holistic and meaningful manner. The second taxonomy system focuses on the evaluation methodologies. It categorizes approaches into annotation-based evaluations, automated metrics, hybrid strategies that combine human assessments with quantitative measures, and self-judging methods utilizing LLMs. This framework not only captures traditional metrics derived from language understanding, such as BLEU and ROUGE scores, but also incorporates advanced techniques that reflect the dynamic, interactive nature of multi-turn dialogues.",2025-03-28,"['cs.CL', 'cs.AI']",http://arxiv.org/pdf/2503.22458v1,survey examines evaluation method large language model llmbased agent multiturn conversational setting using prismainspired framework systematically reviewed nearly 250 scholarly source capturing state art various venue publication establishing solid foundation analysis study offer structured approach developing two interrelated taxonomy system one defines emphwhat evaluate another explains emphhow evaluate first taxonomy identifies key component llmbased agent multiturn conversation evaluation dimension including task completion response quality user experience memory context retention well planning tool integration component ensure performance conversational agent assessed holistic meaningful manner second taxonomy system focus evaluation methodology categorizes approach annotationbased evaluation automated metric hybrid strategy combine human assessment quantitative measure selfjudging method utilizing llm framework capture traditional metric derived language understanding bleu rouge score also incorporates advanced technique reflect dynamic interactive nature multiturn dialogue
2503.22456v1,Entropy-guided sequence weighting for efficient exploration in RL-based LLM fine-tuning,['Abdullah Vanlioglu'],"We introduce Entropy-Guided Sequence Weighting (EGSW), a novel approach that enhances the exploration-exploitation tradeoff by dynamically assigning weights to generated outputs based on their advantage and entropy for Reinforcement Learning-based Large Language Model fine-tuning. EGSW integrates entropy regularization with advantage-based weighting to balance policy updates, enabling efficient exploration in high-dimensional state spaces. By employing temperature-scaled softmax weighting over sequences, EGSW prioritizing high-reward, high-uncertainty steps while maintaining training stability. Although originally developed to improve Group Relative Policy Optimization (GRPO) during large language model (LLM) fine-tuning, EGSW is generalizable to other reinforcement learning (RL) algorithms and can be implemented in both step-wise and trajectory-wise settings. Empirical evaluations demonstrate that EGSW enhances GRPO reasoning ability, yielding improvements in sample efficiency. Future work will explore the application of EGSW to advanced RL methodologies.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22456v1,introduce entropyguided sequence weighting egsw novel approach enhances explorationexploitation tradeoff dynamically assigning weight generated output based advantage entropy reinforcement learningbased large language model finetuning egsw integrates entropy regularization advantagebased weighting balance policy update enabling efficient exploration highdimensional state space employing temperaturescaled softmax weighting sequence egsw prioritizing highreward highuncertainty step maintaining training stability although originally developed improve group relative policy optimization grpo large language model llm finetuning egsw generalizable reinforcement learning rl algorithm implemented stepwise trajectorywise setting empirical evaluation demonstrate egsw enhances grpo reasoning ability yielding improvement sample efficiency future work explore application egsw advanced rl methodology
2503.22455v1,A high order multigrid-preconditioned immersed interface solver for the Poisson equation with boundary and interface conditions,"['James Gabbard', 'Andrea Paris', 'Wim M. van Rees']","This work presents a multigrid preconditioned high order immersed finite difference solver to accurately and efficiently solve the Poisson equation on complex 2D and 3D domains. The solver employs a low order Shortley-Weller multigrid method to precondition a high order matrix-free Krylov subspace solver. The matrix-free approach enables full compatibility with high order IIM discretizations of boundary and interface conditions, as well as high order wavelet-adapted multiresolution grids. Through verification and analysis on 2D domains, we demonstrate the ability of the algorithm to provide high order accurate results to Laplace and Poisson problems with Dirichlet, Neumann, and/or interface jump boundary conditions, all effectively preconditioned using the multigrid method. We further show that the proposed method is able to efficiently solve high order discretizations of Laplace and Poisson problems on complex 3D domains using thousands of compute cores and on multiresolution grids. To our knowledge, this work presents the largest problem sizes tackled with high order immersed methods applied to elliptic partial differential equations, and the first high order results on 3D multiresolution adaptive grids. Together, this work paves the way for employing high order immersed methods to a variety of 3D partial differential equations with boundary or inter-face conditions, including linear and non-linear elasticity problems, the incompressible Navier-Stokes equations, and fluid-structure interactions.",2025-03-28,"['math.NA', 'cs.CE', 'cs.NA']",http://arxiv.org/pdf/2503.22455v1,work present multigrid preconditioned high order immersed finite difference solver accurately efficiently solve poisson equation complex 2d 3d domain solver employ low order shortleyweller multigrid method precondition high order matrixfree krylov subspace solver matrixfree approach enables full compatibility high order iim discretizations boundary interface condition well high order waveletadapted multiresolution grid verification analysis 2d domain demonstrate ability algorithm provide high order accurate result laplace poisson problem dirichlet neumann andor interface jump boundary condition effectively preconditioned using multigrid method show proposed method able efficiently solve high order discretizations laplace poisson problem complex 3d domain using thousand compute core multiresolution grid knowledge work present largest problem size tackled high order immersed method applied elliptic partial differential equation first high order result 3d multiresolution adaptive grid together work pave way employing high order immersed method variety 3d partial differential equation boundary interface condition including linear nonlinear elasticity problem incompressible navierstokes equation fluidstructure interaction
2503.22454v1,A Causal Framework to Measure and Mitigate Non-binary Treatment Discrimination,"['Ayan Majumdar', 'Deborah D. Kanubala', 'Kavya Gupta', 'Isabel Valera']","Fairness studies of algorithmic decision-making systems often simplify complex decision processes, such as bail or loan approvals, into binary classification tasks. However, these approaches overlook that such decisions are not inherently binary (e.g., approve or not approve bail or loan); they also involve non-binary treatment decisions (e.g., bail conditions or loan terms) that can influence the downstream outcomes (e.g., loan repayment or reoffending). In this paper, we argue that non-binary treatment decisions are integral to the decision process and controlled by decision-makers and, therefore, should be central to fairness analyses in algorithmic decision-making. We propose a causal framework that extends fairness analyses and explicitly distinguishes between decision-subjects' covariates and the treatment decisions. This specification allows decision-makers to use our framework to (i) measure treatment disparity and its downstream effects in historical data and, using counterfactual reasoning, (ii) mitigate the impact of past unfair treatment decisions when automating decision-making. We use our framework to empirically analyze four widely used loan approval datasets to reveal potential disparity in non-binary treatment decisions and their discriminatory impact on outcomes, highlighting the need to incorporate treatment decisions in fairness assessments. Moreover, by intervening in treatment decisions, we show that our framework effectively mitigates treatment discrimination from historical data to ensure fair risk score estimation and (non-binary) decision-making processes that benefit all stakeholders.",2025-03-28,"['cs.LG', 'cs.AI']",http://arxiv.org/pdf/2503.22454v1,fairness study algorithmic decisionmaking system often simplify complex decision process bail loan approval binary classification task however approach overlook decision inherently binary eg approve approve bail loan also involve nonbinary treatment decision eg bail condition loan term influence downstream outcome eg loan repayment reoffending paper argue nonbinary treatment decision integral decision process controlled decisionmakers therefore central fairness analysis algorithmic decisionmaking propose causal framework extends fairness analysis explicitly distinguishes decisionsubjects covariates treatment decision specification allows decisionmakers use framework measure treatment disparity downstream effect historical data using counterfactual reasoning ii mitigate impact past unfair treatment decision automating decisionmaking use framework empirically analyze four widely used loan approval datasets reveal potential disparity nonbinary treatment decision discriminatory impact outcome highlighting need incorporate treatment decision fairness assessment moreover intervening treatment decision show framework effectively mitigates treatment discrimination historical data ensure fair risk score estimation nonbinary decisionmaking process benefit stakeholder
2503.22452v1,On the Solvability of Byzantine-tolerant Reliable Communication in Dynamic Networks,"['Silvia Bonomi', 'Giovanni Farina', 'Sébastien Tixeuil']","A reliable communication primitive guarantees the delivery, integrity, and authorship of messages exchanged between processes of a distributed system. We investigate the necessary and sufficient conditions for reliable communication in dynamic networks, where the network topology evolves over time despite the presence of a limited number of Byzantine faulty processes that may behave arbitrarily (i.e., in the globally bounded Byzantine failure model). We identify classes of dynamic networks where such conditions are satisfied, and extend our analysis to message losses, local computation with unbounded finite delay, and authenticated messages. Our investigation builds on the seminal characterization by Maurer, Tixeuil, and D{\'e}fago (2015).",2025-03-28,['cs.DC'],http://arxiv.org/pdf/2503.22452v1,reliable communication primitive guarantee delivery integrity authorship message exchanged process distributed system investigate necessary sufficient condition reliable communication dynamic network network topology evolves time despite presence limited number byzantine faulty process may behave arbitrarily ie globally bounded byzantine failure model identify class dynamic network condition satisfied extend analysis message loss local computation unbounded finite delay authenticated message investigation build seminal characterization maurer tixeuil defago 2015
2503.22451v1,STADE: Standard Deviation as a Pruning Metric,"['Diego Coello de Portugal Mecke', 'Haya Alyoussef', 'Ilia Koloiarov', 'Maximilian Stubbemann', 'Lars Schmidt-Thieme']","Recently, Large Language Models (LLMs) have become very widespread and are used to solve a wide variety of tasks. To successfully handle these tasks, LLMs require longer training times and larger model sizes. This makes LLMs ideal candidates for pruning methods that reduce computational demands while maintaining performance. Previous methods require a retraining phase after pruning to maintain the original model's performance. However, state-of-the-art pruning methods, such as Wanda, prune the model without retraining, making the pruning process faster and more efficient. Building upon Wanda's work, this study provides a theoretical explanation of why the method is effective and leverages these insights to enhance the pruning process. Specifically, a theoretical analysis of the pruning problem reveals a common scenario in Machine Learning where Wanda is the optimal pruning method. Furthermore, this analysis is extended to cases where Wanda is no longer optimal, leading to the development of a new method, STADE, based on the standard deviation of the input. From a theoretical standpoint, STADE demonstrates better generality across different scenarios. Finally, extensive experiments on Llama and Open Pre-trained Transformers (OPT) models validate these theoretical findings, showing that depending on the training conditions, Wanda's optimal performance varies as predicted by the theoretical framework. These insights contribute to a more robust understanding of pruning strategies and their practical implications. Code is available at: https://github.com/Coello-dev/STADE/",2025-03-28,['cs.LG'],http://arxiv.org/pdf/2503.22451v1,recently large language model llm become widespread used solve wide variety task successfully handle task llm require longer training time larger model size make llm ideal candidate pruning method reduce computational demand maintaining performance previous method require retraining phase pruning maintain original model performance however stateoftheart pruning method wanda prune model without retraining making pruning process faster efficient building upon wandas work study provides theoretical explanation method effective leverage insight enhance pruning process specifically theoretical analysis pruning problem reveals common scenario machine learning wanda optimal pruning method furthermore analysis extended case wanda longer optimal leading development new method stade based standard deviation input theoretical standpoint stade demonstrates better generality across different scenario finally extensive experiment llama open pretrained transformer opt model validate theoretical finding showing depending training condition wandas optimal performance varies predicted theoretical framework insight contribute robust understanding pruning strategy practical implication code available httpsgithubcomcoellodevstade
2503.22449v1,Polychromatic Coloring of Tuples in Hypergraphs,"['Ahmad Biniaz', 'Jean-Lou De Carufel', 'Anil Maheshwari', 'Michiel Smid', 'Shakhar Smorodinsky', 'Miloš Stojaković']","A hypergraph $H$ consists of a set $V$ of vertices and a set $E$ of hyperedges that are subsets of $V$. A $t$-tuple of $H$ is a subset of $t$ vertices of $V$. A $t$-tuple $k$-coloring of $H$ is a mapping of its $t$-tuples into $k$ colors. A coloring is called $(t,k,f)$-polychromatic if each hyperedge of $E$ that has at least $f$ vertices contains tuples of all the $k$ colors. Let $f_H(t,k)$ be the minimum $f$ such that $H$ has a $(t,k,f)$-polychromatic coloring. For a family of hypergraphs $\cal{H}$ let $f_{\cal{H}}(t,k)$ be the maximum $f_H(t,k)$ over all hypergraphs $H$ in $\cal{H}$. We present several bounds on $f_{\cal{H}}(t,k)$ for $t\ge 2$.   - Let $\cal{H}$ be the family of hypergraphs $H$ that is obtained by taking any set $P$ of points in $\Re^2$, setting $V:=P$ and $E:=\{d\cap P\colon d\text{ is a disk in }\Re^2\}$. We prove that $f_\cal{H}(2,k)\le 3.7^k$, that is, the pairs of points (2-tuples) can be $k$-colored such that any disk containing at least $3.7^k$ points has pairs of all colors.   - For the family $\mathcal{H}$ of shrinkable hypergraphs of VC-dimension at most $d$ we prove that $ f_\cal{H}(d{+}1,k) \leq c^k$ for some constant $c=c(d)$. We also prove that every hypergraph with $n$ vertices and with VC-dimension at most $d$ has a $(d{+}1)$-tuple $T$ of depth at least $\frac{n}{c}$, i.e., any hyperedge that contains $T$ also contains $\frac{n}{c}$ other vertices.   - For the relationship between $t$-tuple coloring and vertex coloring in any hypergraph $H$ we establish the inequality $\frac{1}{e}\cdot tk^{\frac{1}{t}}\le f_H(t,k)\le f_H(1,tk^{\frac{1}{t}})$. For the special case of $k=2$, we prove that $t+1\le f_H(t,2)\le\max\{f_H(1,2), t+1\}$; this improves upon the previous best known upper bound.   - We generalize some of our results to higher dimensions, other shapes, pseudo-disks, and also study the relationship between tuple coloring and epsilon nets.",2025-03-28,['cs.CG'],http://arxiv.org/pdf/2503.22449v1,hypergraph h consists set v vertex set e hyperedges subset v ttuple h subset vertex v ttuple kcoloring h mapping ttuples k color coloring called tkfpolychromatic hyperedge e least f vertex contains tuples k color let fhtk minimum f h tkfpolychromatic coloring family hypergraphs calh let fcalhtk maximum fhtk hypergraphs h calh present several bound fcalhtk tge 2 let calh family hypergraphs h obtained taking set p point re2 setting vp edcap pcolon dtext disk re2 prove fcalh2kle 37k pair point 2tuples kcolored disk containing least 37k point pair color family mathcalh shrinkable hypergraphs vcdimension prove fcalhd1k leq ck constant ccd also prove every hypergraph n vertex vcdimension d1tuple depth least fracnc ie hyperedge contains also contains fracnc vertex relationship ttuple coloring vertex coloring hypergraph h establish inequality frac1ecdot tkfrac1tle fhtkle fh1tkfrac1t special case k2 prove t1le fht2lemaxfh12 t1 improves upon previous best known upper bound generalize result higher dimension shape pseudodisks also study relationship tuple coloring epsilon net
2503.22448v1,"Comparison between neural network clustering, hierarchical clustering and k-means clustering: Applications using fluidic lenses",['Graciana Puentes'],"A comparison between neural network clustering (NNC), hierarchical clustering (HC) and K-means clustering (KMC) is performed to evaluate the computational superiority of these three machine learning (ML) techniques for organizing large datasets into clusters. For NNC, a self-organizing map (SOM) training was applied to a collection of wavefront sensor reconstructions, decomposed in terms of 15 Zernike coefficients, characterizing the optical aberrations of the phase front transmitted by fluidic lenses. In order to understand the distribution and structure of the 15 Zernike variables within an input space, SOM-neighboring weight distances, SOM-sample hits, SOM-weight positions and SOM-weight planes were analyzed to form a visual interpretation of the system's structural properties. In the case of HC, the data was partitioned using a combined dissimilarity-linkage matrix computation. The effectiveness of this method was confirmed by a high cophenetic correlation coefficient value (c=0.9651). Additionally, a maximum number of clusters was established by setting an inconsistency cutoff of 0.8, yielding a total of 7 clusters for system segmentation. In addition, a KMC approach was employed to establish a quantitative measure of clustering segmentation efficiency, obtaining a sillhoute average value of 0.905 for data segmentation into K=5 non-overlapping clusters. On the other hand, the NNC analysis revealed that the 15 variables could be characterized through the collective influence of 8 clusters. It was established that the formation of clusters through the combined linkage and dissimilarity algorithms of HC alongside KMC is a more dependable clustering solution than separate assessment via NNC or HC, where altering the SOM size or inconsistency cutoff can lead to completely new clustering configurations.",2025-03-28,"['physics.optics', 'cs.LG']",http://arxiv.org/pdf/2503.22448v1,comparison neural network clustering nnc hierarchical clustering hc kmeans clustering kmc performed evaluate computational superiority three machine learning ml technique organizing large datasets cluster nnc selforganizing map som training applied collection wavefront sensor reconstruction decomposed term 15 zernike coefficient characterizing optical aberration phase front transmitted fluidic lens order understand distribution structure 15 zernike variable within input space somneighboring weight distance somsample hit somweight position somweight plane analyzed form visual interpretation system structural property case hc data partitioned using combined dissimilaritylinkage matrix computation effectiveness method confirmed high cophenetic correlation coefficient value c09651 additionally maximum number cluster established setting inconsistency cutoff 08 yielding total 7 cluster system segmentation addition kmc approach employed establish quantitative measure clustering segmentation efficiency obtaining sillhoute average value 0905 data segmentation k5 nonoverlapping cluster hand nnc analysis revealed 15 variable could characterized collective influence 8 cluster established formation cluster combined linkage dissimilarity algorithm hc alongside kmc dependable clustering solution separate assessment via nnc hc altering som size inconsistency cutoff lead completely new clustering configuration
