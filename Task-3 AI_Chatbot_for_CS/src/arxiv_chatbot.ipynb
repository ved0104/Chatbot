# -*- coding: utf-8 -*-
"""
Created on [Date]

@author: [Your Name]
arXiv Domain Chatbot (Computer Science Focus)
"""
# %% [markdown]
# ## 2. Data Loading & Preprocessing

# %%
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import spacy

# Load arXiv dataset
df = pd.read_csv('arxiv_data.csv')  # Replace with your dataset path
cs_df = df[df['categories'].str.contains('cs.')].copy()

# Preprocessing
nlp = spacy.load("en_core_web_sm")

def preprocess(text):
    doc = nlp(text.lower())
    return " ".join([token.lemma_ for token in doc if not token.is_stop and token.is_alpha])

cs_df['processed_text'] = cs_df['abstract'].apply(preprocess)

# %% [markdown]
# ## 3. Model Initialization

# %%
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
from sentence_transformers import SentenceTransformer

# Load models
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
qa_model = pipeline("text-generation", model="mistralai/Mistral-7B-Instruct-v0.2")
embedder = SentenceTransformer('all-mpnet-base-v2')

# Create semantic search index
paper_embeddings = embedder.encode(cs_df['processed_text'].tolist())

# %% [markdown]
# ## 4. Core Functions

# %%
import numpy as np
import faiss

class ChatSystem:
    def __init__(self):
        self.context = []
        self.index = faiss.IndexFlatL2(768)
        self.index.add(paper_embeddings)
        
    def semantic_search(self, query, k=3):
        query_embed = embedder.encode([query])
        distances, indices = self.index.search(query_embed, k)
        return cs_df.iloc[indices[0].tolist()]
    
    def generate_summary(self, text):
        return summarizer(text, max_length=150, min_length=30, do_sample=False)[0]['summary_text']
    
    def explain_concept(self, concept):
        prompt = f"""Explain {concept} in simple terms for a computer science graduate student. 
        Include key equations if relevant and cite papers from the arXiv dataset."""
        return qa_model(prompt, max_new_tokens=500)[0]['generated_text']
    
    def handle_query(self, user_input):
        # Intent recognition
        if "summarize" in user_input.lower():
            papers = self.semantic_search(user_input)
            return self.generate_summary(papers.iloc[0]['abstract'])
        elif "explain" in user_input.lower():
            concept = user_input.split("explain")[-1].strip()
            return self.explain_concept(concept)
        else:
            return qa_model(user_input, max_new_tokens=300)[0]['generated_text']

# %% [markdown]
# ## 5. Streamlit Interface (Run Separately)

# %%
%%writefile app.py
import streamlit as st
import plotly.express as px
from ChatSystem import ChatSystem  # Assuming previous code is saved as ChatSystem.py

st.title("arXiv Computer Science Chatbot")
chat_system = ChatSystem()

user_input = st.text_input("Ask your question about CS research:")
if user_input:
    response = chat_system.handle_query(user_input)
    st.write("Response:", response)
    
    # Visualization
    papers = chat_system.semantic_search(user_input)
    fig = px.scatter(papers, x='published', y='authors', 
                    size='citation_count', hover_data=['title'])
    st.plotly_chart(fig)

# %% [markdown]
# ## 6. Execution Instructions
# To run the Streamlit app:
# ```bash
# streamlit run app.py
# ```

# %% [markdown]
# ## 7. Evaluation Metrics

# %%
from rouge_score import rouge_scorer

def evaluate_response(predicted, reference):
    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)
    return scorer.score(predicted, reference)

# Example usage
test_question = "Explain attention mechanisms in transformers"
expected_answer = """Attention mechanisms allow models to focus on relevant..."""
generated = chat_system.handle_query(test_question)
print(evaluate_response(generated, expected_answer))
